{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/aliahmadi/Documents/Projects/RNA-Secondary-Structure-Prediction/notebook/EKH-25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.linalg import expm\n",
    "from grammar.pcnf import PCNF\n",
    "from Bio import Phylo, SeqIO\n",
    "from copy import deepcopy\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "from math import log \n",
    "import numpy as np\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IUPAC Nucleotide table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iupac_nucleotides = {\n",
    "    'A':[\"A\"],\n",
    "    'C':[\"C\"],\n",
    "    'G':[\"G\"],\n",
    "    'U':[\"U\"], \n",
    "    'R':[\"A\", \"G\"], \n",
    "    'Y':[\"C\", \"U\"],\n",
    "    'S':[\"G\", \"C\"],\n",
    "    'W':[\"A\", \"U\"],\n",
    "    'K':[\"G\", \"U\"],\n",
    "    'M':[\"A\", \"C\"],\n",
    "    'B':[\"C\", \"G\", \"U\"],\n",
    "    'D':[\"A\", \"G\", \"U\"],\n",
    "    'H':[\"A\", \"C\", \"U\"],\n",
    "    'V':[\"A\", \"C\", \"G\"],\n",
    "    'N':[\"A\", \"C\", \"G\", \"U\"],\n",
    "    '-': [\"-\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = defaultdict(lambda: Phylo.read(StringIO(\"();\"), \"newick\"))\n",
    "sequences = defaultdict(lambda: defaultdict(str))\n",
    "structures = defaultdict(str)\n",
    "\n",
    "predicted_struct = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairing Charecters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_start(pair_end):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return [val for val in pairing_chars if val[1] == pair_end][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pair_start(char):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return char in [p[0] for p in pairing_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pair_end(char):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return char in [p[1] for p in pairing_chars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_str(input_string, valid_characters = ['A','C', 'G', 'U']):\n",
    "    for char in input_string:\n",
    "        if char not in valid_characters:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clade_names_fix(tree):\n",
    "    for index, clade in enumerate(tree.find_clades()):\n",
    "        if not clade.name:\n",
    "            clade.name = str(index)\n",
    "\n",
    "def read_tree(filename: str):\n",
    "    Tree = Phylo.read(filename, 'newick')\n",
    "    clade_names_fix(Tree)\n",
    "    return Tree\n",
    "\n",
    "def open_tree(filename: str, dataset_name):\n",
    "    Tree = Phylo.read(filename, 'newick')\n",
    "    clade_names_fix(Tree)\n",
    "    \n",
    "    trees[dataset_name] = Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sequences (filename: str, dataset_name):\n",
    "    dataset = defaultdict(str)\n",
    "    \n",
    "    with open(filename) as file:\n",
    "        records = SeqIO.parse(file, \"phylip-relaxed\")\n",
    "        count = 0\n",
    "        \n",
    "        for record in records:\n",
    "            dataset[record.id] = record.seq\n",
    "            count += 1\n",
    "           \n",
    "        dataset[\"_weight\"] = 1000 / count   \n",
    "        \n",
    "    sequences[dataset_name] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_structure(filename: str, dataset_name):\n",
    "    with open(filename) as file:\n",
    "        structures[dataset_name] = file.readline().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_struct(structures, filename=\"./primaries/structures\"):\n",
    "    pairing_chars = [\"<\", \">\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    simplified = \"\"\n",
    "    for _, structure in structures.items():\n",
    "        for i in range(len(structure)):\n",
    "            if structure[i] in pairing_chars:\n",
    "                simplified += \"d \"\n",
    "            else:\n",
    "                simplified += \"s \"\n",
    "        simplified += \"\\n\"\n",
    "    \n",
    "    simplified = simplified.rstrip('\\n')\n",
    "    \n",
    "    if filename != \"\":        \n",
    "        with open(f\"{filename}.train\", \"w+\") as file:\n",
    "            file.write(simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(input_sequences, filename = \"./outputs/tree.nwk\", draw=False):\n",
    "  names = list(input_sequences.keys())\n",
    "  sequences = list(input_sequences.values())\n",
    "  \n",
    "  if len(names) <= 2:\n",
    "    return None\n",
    "  \n",
    "  os.mkdir(\"./tmp\")\n",
    "\n",
    "  if len(names) > 2:\n",
    "    phylip_file = \"./tmp/sequences.phylip\"\n",
    "    with open(phylip_file, \"w\") as f:\n",
    "      f.write(f\"{len(sequences)} {len(sequences[0])}\\n\\n\")\n",
    "      for i, seq in enumerate(sequences):\n",
    "        f.write(f\"{names[i]}\\t{seq}\\n\") \n",
    "    \n",
    "    # !./phyml -i tmp/sequences.phylip -m GTR\n",
    "    !./phyml -i tmp/sequences.phylip -m GTR > /dev/null 2>&1\n",
    "\n",
    "    \n",
    "    output_tree = Phylo.read(phylip_file + \"_phyml_tree.txt\", 'newick')\n",
    "\n",
    "    output_tree.root_at_midpoint()\n",
    "  \n",
    "  for index, clade in enumerate(output_tree.find_clades()):\n",
    "    if not clade.name:\n",
    "      clade.name = str(index)\n",
    "  \n",
    "  shutil.rmtree(\"./tmp\")\n",
    "  Phylo.write(output_tree, filename, \"newick\")\n",
    "  if draw:\n",
    "    Phylo.draw(output_tree)\n",
    "  \n",
    "  return output_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_frequencies (sequences, structures):\n",
    "    single_nucleotides = defaultdict(int)\n",
    "    paired_nucleotides = defaultdict(int)\n",
    "    \n",
    "    total_singles = 0\n",
    "    total_paireds = 0\n",
    "    \n",
    "    # Stack of unpaired nucleotides (structure symbol, nocleotide)\n",
    "    unpaired_nucleotides = []\n",
    "    for dataset_name, dataset_values in sequences.items():\n",
    "        sequences_weight = dataset_values[\"_weight\"]\n",
    "        dataset_sequences = [v for k, v in dataset_values.items() if k != \"_weight\"]\n",
    "        dataset_structure = structures[dataset_name]\n",
    "        for sequence in dataset_sequences:\n",
    "            for index, nucleotide in enumerate(sequence): \n",
    "                structure_symbol = dataset_structure[index]\n",
    "                # Having a charecter [ '(', '[', '{', '<' ]\n",
    "                if is_pair_start(structure_symbol):\n",
    "                    unpaired_nucleotides.append((structure_symbol, iupac_nucleotides[nucleotide]))\n",
    "                # Having a charecter [ ')', ']', '}', '>' ]\n",
    "                elif is_pair_end(structure_symbol):\n",
    "                    unpaired_nucleotide = unpaired_nucleotides.pop()\n",
    "                    if unpaired_nucleotide[0] == get_pair_start(structure_symbol):\n",
    "                        targets = [f\"{nucl1}{nucl2}\" \n",
    "                            for nucl1 in unpaired_nucleotide[1] \n",
    "                            for nucl2 in iupac_nucleotides[nucleotide]\n",
    "                        ]\n",
    "                        for target in targets:\n",
    "                            if is_valid_str(target):\n",
    "                                # print(len(targets))\n",
    "                                paired_nucleotides[target] += sequences_weight / len(targets)\n",
    "                                paired_nucleotides[target[::-1]] += sequences_weight / len(targets)\n",
    "                                \n",
    "                                total_paireds += sequences_weight / len(targets)\n",
    "                    else:\n",
    "                        raise ValueError('Invalid pattern in structure')\n",
    "                # Having a non-pairing charecter\n",
    "                else:\n",
    "                    targets = iupac_nucleotides[nucleotide]\n",
    "                    for target in targets:\n",
    "                        if is_valid_str(nucleotide):\n",
    "                            # print(len(targets))\n",
    "                            single_nucleotides[target] += sequences_weight / len(targets)\n",
    "                            \n",
    "                            total_singles += sequences_weight / len(targets)\n",
    "\n",
    "    total = total_singles + (total_paireds * 2)\n",
    "                \n",
    "    for key, value in single_nucleotides.items():\n",
    "        single_nucleotides[key] = value / total_singles\n",
    "    for key, value in paired_nucleotides.items():\n",
    "        paired_nucleotides[key] = value / (total_paireds * 2)\n",
    "        \n",
    "    return (\n",
    "        single_nucleotides,\n",
    "        paired_nucleotides,\n",
    "        total_singles / total,\n",
    "        (total_paireds * 2) / total\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check simularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_simularity(seq1:str, seq2:str):\n",
    "    simularity = 0\n",
    "    if len(seq1) == len(seq2):\n",
    "        for i in range(len(seq1)):\n",
    "            if seq1[i] == seq2[i]:\n",
    "                simularity += 1\n",
    "        return simularity / len(seq1) >= .85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(seq1: str, seq2: str) -> bool:\n",
    "    # Validate input\n",
    "    if len(seq1) != len(seq2):\n",
    "        return False  # Sequences must be of the same length\n",
    "\n",
    "    # Define nucleotide groups\n",
    "    pyrimidines = {'C', 'U'}  # Cytosine, Uracil\n",
    "    purines = {'A', 'G'}      # Adenine, Guanine\n",
    "\n",
    "    # Initialize similarity count\n",
    "    similarity = 0\n",
    "\n",
    "    for i in range(len(seq1)):\n",
    "        # Handle IUPAC codes\n",
    "        possible_nucleotides1 = iupac_nucleotides.get(seq1[i], [seq1[i]])\n",
    "        possible_nucleotides2 = iupac_nucleotides.get(seq2[i], [seq2[i]])\n",
    "        \n",
    "        match_score = 0\n",
    "        for n1 in possible_nucleotides1:\n",
    "            for n2 in possible_nucleotides2:\n",
    "                if n1 == n2:\n",
    "                    match_score += 1 / (len(possible_nucleotides1) * len(possible_nucleotides2))\n",
    "                elif (n1 in pyrimidines and n2 in pyrimidines) or (n1 in purines and n2 in purines):\n",
    "                    match_score += 0.5 / (len(possible_nucleotides1) * len(possible_nucleotides2))                    \n",
    "        \n",
    "        similarity += match_score \n",
    "\n",
    "    # Calculate final similarity ratio\n",
    "    similarity_ratio = similarity / len(seq1)\n",
    "\n",
    "    return similarity_ratio >= 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Rate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rate_values(\n",
    "    trees,\n",
    "    sequences: defaultdict, \n",
    "    structures, \n",
    "    single_frequencies, \n",
    "    paired_frequencies, \n",
    "    singles_prob, \n",
    "    paireds_prob\n",
    "):\n",
    "    unpaired_nucleotides = []\n",
    "    \n",
    "    single_mutation_count = defaultdict(float)\n",
    "    paired_mutation_count = defaultdict(float)\n",
    "    k_value = 0\n",
    "    \n",
    "    for dataset_name, dataset_values in sequences.items():\n",
    "        sequences_weight = dataset_values[\"_weight\"]\n",
    "        dataset_sequences = [(k, v) for k, v in dataset_values.items() if k != \"_weight\"]\n",
    "        dataset_structure = structures[dataset_name]\n",
    "        \n",
    "        for i in range(len(dataset_sequences)):\n",
    "            temp_single_mutation_count = defaultdict(int)\n",
    "            temp_paired_mutation_count = defaultdict(int)\n",
    "            k_temp = 0\n",
    "            \n",
    "            same_first_sequence_count = 0\n",
    "            \n",
    "            for j in range(len(dataset_sequences)):\n",
    "                columns_count = 0\n",
    "                \n",
    "                first_name = dataset_sequences[i][0]\n",
    "                second_name = dataset_sequences[j][0]\n",
    "                first_sequence = dataset_sequences[i][1]\n",
    "                second_sequence = dataset_sequences[j][1]\n",
    "                # The pair should contain diffrent \n",
    "                # sequence with at least %85 simularity.\n",
    "                if i != j and check_simularity(first_sequence, second_sequence):\n",
    "                    same_first_sequence_count += 1\n",
    "                    for k in range(len(first_sequence)): \n",
    "                        structure_symbol = dataset_structure[k]\n",
    "                        # Having a charecter [ '(', '[', '{', '<' ]\n",
    "                        if is_pair_start(structure_symbol):\n",
    "                            unpaired_nucleotides.append((\n",
    "                                structure_symbol, \n",
    "                                iupac_nucleotides[first_sequence[k]],\n",
    "                                iupac_nucleotides[second_sequence[k]]\n",
    "                            ))\n",
    "                        # Having a charecter [ ')', ']', '}', '>' ]\n",
    "                        elif is_pair_end(structure_symbol):\n",
    "                            unpaired_nucleotide = unpaired_nucleotides.pop()\n",
    "                            \n",
    "                            first_side_targets = [f\"{nucl1}{nucl2}\" \n",
    "                                for nucl1 in unpaired_nucleotide[1] \n",
    "                                for nucl2 in iupac_nucleotides[first_sequence[k]]\n",
    "                            ]\n",
    "                            second_side_targets = [f\"{nucl1}{nucl2}\" \n",
    "                                for nucl1 in unpaired_nucleotide[2] \n",
    "                                for nucl2 in iupac_nucleotides[second_sequence[k]]\n",
    "                            ]\n",
    "                            \n",
    "                            if unpaired_nucleotide[0] == get_pair_start(structure_symbol):\n",
    "                                for first_side in first_side_targets:\n",
    "                                    for second_side in second_side_targets:\n",
    "                                        if (is_valid_str(first_side) \n",
    "                                        and is_valid_str(second_side)):\n",
    "                                            columns_count += (2 * sequences_weight) / (len(first_side_targets) * len(second_side_targets))\n",
    "                                            \n",
    "                                            if first_side != second_side:\n",
    "                                                temp_paired_mutation_count[\n",
    "                                                    (first_side, second_side)\n",
    "                                                ] += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                                                temp_paired_mutation_count[\n",
    "                                                    (first_side[::-1], second_side[::-1])\n",
    "                                                ] += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                            else:\n",
    "                                raise ValueError('Invalid pattern in structure')    \n",
    "                        # Having a non-pairing charecter\n",
    "                        else:\n",
    "                            first_side_targets = iupac_nucleotides[first_sequence[k]]\n",
    "                            second_side_targets = iupac_nucleotides[second_sequence[k]]\n",
    "                            \n",
    "                            for first_side in first_side_targets:\n",
    "                                for second_side in second_side_targets:\n",
    "                                    if (is_valid_str(first_side) \n",
    "                                    and is_valid_str(second_side)):\n",
    "                                        columns_count += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                                        if first_side != second_side:\n",
    "                                            temp_single_mutation_count[(\n",
    "                                                first_side, \n",
    "                                                second_side,\n",
    "                                            )] += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                    \n",
    "                    k_temp += (trees[dataset_name].distance(\n",
    "                        first_name, \n",
    "                        second_name\n",
    "                    ) * columns_count)\n",
    "                    \n",
    "            \n",
    "            if same_first_sequence_count > 0:\n",
    "                k_value += (k_temp / same_first_sequence_count)\n",
    "                \n",
    "                for key in temp_single_mutation_count:\n",
    "                    single_mutation_count[key] += (temp_single_mutation_count[key] \n",
    "                                                / same_first_sequence_count)\n",
    "                for key in temp_paired_mutation_count:\n",
    "                    paired_mutation_count[key] += (temp_paired_mutation_count[key] \n",
    "                                                / same_first_sequence_count)\n",
    "                \n",
    "    single_chars = [\"A\", \"C\", \"G\", \"U\"]\n",
    "    paired_chars = [c1 + c2 for c1 in single_chars for c2 in single_chars]\n",
    "    \n",
    "    single_rate_values = defaultdict(float)\n",
    "    paired_rate_values = defaultdict(float)\n",
    "            \n",
    "    for i in single_chars:\n",
    "        single_rate_values[(i,i)] = 0\n",
    "        for j in single_chars:\n",
    "            if i != j:\n",
    "                single_rate_values[(i,j)] = (single_mutation_count[(i,j)] \n",
    "                                             / (singles_prob * single_frequencies[i] * k_value))\n",
    "                single_rate_values[(i,i)] = single_rate_values[(i,i)] - single_rate_values[(i,j)]\n",
    "\n",
    "    for i in paired_chars:\n",
    "        paired_rate_values[(i,i)] = 0\n",
    "        for j in paired_chars:\n",
    "            if i != j:\n",
    "                paired_rate_values[(i,j)] = ((paired_mutation_count[(i,j)] * 2)\n",
    "                                             / (paireds_prob * paired_frequencies[i] * k_value))\n",
    "                paired_rate_values[(i,i)] = paired_rate_values[(i,i)] - paired_rate_values[(i,j)]\n",
    "    \n",
    "    return single_rate_values, paired_rate_values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mutation Probablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutation_probablities(mutation_rate_values, time, order_array = [\"A\", \"C\", \"G\", \"U\"], gappy=False):\n",
    "    mutation_rate_matrix = np.zeros((len(order_array), len(order_array)), np.float64)\n",
    "    \n",
    "    for i_index, i_value in enumerate(order_array):\n",
    "        for j_index, j_value in enumerate(order_array):\n",
    "            mutation_rate_matrix[i_index,j_index] = mutation_rate_values[(i_value, j_value)]\n",
    "    \n",
    "    probability_rate_matrix = expm(mutation_rate_matrix * time)\n",
    "    \n",
    "    probability_rate_values = defaultdict(float)\n",
    "    for i_index, i_value in enumerate(order_array):\n",
    "        for j_index, j_value in enumerate(order_array):\n",
    "            probability_rate_values[(i_value, j_value)] = probability_rate_matrix[i_index,j_index]\n",
    "            \n",
    "    if gappy:      \n",
    "        if order_array == [\"A\", \"C\", \"G\", \"U\"]:\n",
    "            for i_index, i_value in enumerate(order_array):\n",
    "                for _, j_value in enumerate([\"-\"]):\n",
    "                    probability_rate_values[(i_value, j_value)] = 1\n",
    "        else:\n",
    "            for i_index, i_value in enumerate(order_array):\n",
    "                for j_index, j_value in enumerate(['A-', '-A', 'C-', '-C', 'G-', '-G', 'U-', '-U', '--']):\n",
    "                    if j_value == \"--\":\n",
    "                        probability_rate_values[(i_value, j_value)] = 1\n",
    "                    else:\n",
    "                        __probability = 0\n",
    "                        for nocleotid in [\"A\", \"C\", \"G\", \"U\"]:\n",
    "                            __j_value = j_value.replace('-', nocleotid)\n",
    "                            __probability += probability_rate_values[(i_value, __j_value)]\n",
    "                                \n",
    "                        probability_rate_values[(i_value, j_value)] = __probability\n",
    "    \n",
    "        \n",
    "    return probability_rate_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Successor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_successor(pattern):\n",
    "    order = [\"A\", \"C\", \"G\", \"U\"]\n",
    "    if pattern == ([\"-\"] * len(pattern)):\n",
    "        return []\n",
    "    # last_filled = len(pattern) - 1\n",
    "    for i in range(len(pattern)):\n",
    "        if pattern[i] != \"-\":\n",
    "            if pattern[i] == order[-1]:\n",
    "                if (i == len(pattern) - 1) or (pattern[i+1] == \"-\"):\n",
    "                    pattern[i] = \"-\"\n",
    "                else:\n",
    "                    pattern[i] = order[0]\n",
    "            else:\n",
    "                index = order.index(pattern[i])\n",
    "                pattern[i] = order[index + 1]\n",
    "                return pattern\n",
    "\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_needed(tuple1, tuple2):\n",
    "    return len(tuple1) == len(tuple2) and all(t1 == t2 for t1, t2 in zip(tuple1, tuple2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(input_sequences, leaf_order):\n",
    "    columns = defaultdict(list)\n",
    "    \n",
    "    for i in range(len(list(input_sequences.values())[0])):\n",
    "        column = tuple([\n",
    "            input_sequences[name][i] for name in leaf_order\n",
    "        ])\n",
    "        columns[column].append(i)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_column(input_sequences, column, leaf_order):\n",
    "    __leaf_order = leaf_order[-len(column):]\n",
    "    columns = get_columns(input_sequences, __leaf_order)\n",
    "    \n",
    "    if len(column[0]) == 1:\n",
    "        for _column, _places in columns.items():\n",
    "            if column_needed(column, _column):\n",
    "                return True\n",
    "    else:\n",
    "        for _column1, _places1 in columns.items():\n",
    "            left_column = tuple(\n",
    "                    pair[0] for pair in column if pair\n",
    "            )\n",
    "            if column_needed(left_column, _column1):\n",
    "                for _column2, _places2 in columns.items():\n",
    "                    right_column = tuple(\n",
    "                        pair[1] for pair in column if pair\n",
    "                    )\n",
    "                    if _places2 != [] and column_needed(right_column, _column2):\n",
    "                        if _places1[0] < _places2[-1]:\n",
    "                            return True\n",
    "    \n",
    "    return False       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Order Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_order_traversal(tree, current_node, interior_possible_values, tips_possible_values, rate_values, input_sequences, leaf_order = []): \n",
    "    current_columns_probability = defaultdict(lambda: defaultdict(float))\n",
    "    for child in current_node.clades:\n",
    "        # going to add a branch with a single nucleotide \n",
    "        if child.is_terminal():\n",
    "            leaf_order.append(child.name)\n",
    "            time = tree.distance(\n",
    "                current_node.name, \n",
    "                child.name\n",
    "            )\n",
    "            mutation_probablities = get_mutation_probablities(rate_values, time, interior_possible_values, True)\n",
    "            # have filled with some branch in last iteration\n",
    "            if current_columns_probability:\n",
    "                perv_columns_probability = deepcopy(current_columns_probability)\n",
    "                current_columns_probability.clear()\n",
    "                for left_column in perv_columns_probability:\n",
    "                    for child_value in tips_possible_values:\n",
    "                        if check_column(input_sequences, left_column + (child_value ,), leaf_order):\n",
    "                            for root in perv_columns_probability[left_column]:\n",
    "                                current_columns_probability[left_column + (child_value ,)][root] = (\n",
    "                                    mutation_probablities[(root, child_value)] * \n",
    "                                    perv_columns_probability[left_column][root]\n",
    "                                )\n",
    "                perv_columns_probability.clear()\n",
    "            \n",
    "            # haven't filled with any branch in last iteration\n",
    "            else:\n",
    "                # for mutation in mutation_probablities:\n",
    "                for child_value in tips_possible_values:\n",
    "                    if check_column(input_sequences, (child_value ,), leaf_order):\n",
    "                        for parent_value in interior_possible_values:\n",
    "                            current_columns_probability[(child_value ,)][parent_value] = mutation_probablities[(parent_value, child_value)]\n",
    "        # going to add a branch with a more than one nucleotide \n",
    "        else:    \n",
    "            inner_columns_probability, _ = post_order_traversal(tree, child, interior_possible_values, tips_possible_values, rate_values, input_sequences, leaf_order)\n",
    "            time = tree.distance(\n",
    "                current_node.name, \n",
    "                child.name\n",
    "            )\n",
    "            mutation_probablities = get_mutation_probablities(rate_values, time, interior_possible_values)\n",
    "            \n",
    "            # have filled with some branch in last iteration\n",
    "            if current_columns_probability:\n",
    "                perv_columns_probability = deepcopy(current_columns_probability)\n",
    "                current_columns_probability.clear()\n",
    "                \n",
    "                for left_column in perv_columns_probability:\n",
    "                    for right_column in inner_columns_probability:\n",
    "                        if check_column(input_sequences, left_column + right_column, leaf_order):\n",
    "                            for root in perv_columns_probability[left_column]:\n",
    "                                current_columns_probability[left_column + right_column][root] = sum(\n",
    "                                    (\n",
    "                                        mutation_probablities[(root, inner_root)] * \n",
    "                                        inner_columns_probability[right_column][inner_root] * \n",
    "                                        perv_columns_probability[left_column][root]\n",
    "                                    ) for inner_root in inner_columns_probability[right_column])\n",
    "                \n",
    "                perv_columns_probability.clear()\n",
    "\n",
    "            # haven't filled with some branch in last iteration\n",
    "            else:\n",
    "                for root_value in interior_possible_values:\n",
    "                    for column in inner_columns_probability:\n",
    "                        current_columns_probability[column][root_value] = sum(\n",
    "                            (\n",
    "                                mutation_probablities[(root_value, inner_root)] * \n",
    "                                inner_columns_probability[column][inner_root]\n",
    "                            ) for inner_root in inner_columns_probability[column]\n",
    "                        )\n",
    "                    \n",
    "    return current_columns_probability, leaf_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Columns Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_probability(\n",
    "    tree,  \n",
    "    single_frequencies, \n",
    "    paired_frequencies, \n",
    "    single_rate_values, \n",
    "    paired_rate_values,\n",
    "    input_sequences,\n",
    "):\n",
    "    single_interior_possible_values = ['A', 'C', 'G', 'U']\n",
    "    paired_interior_possible_values = [c1 + c2 for c1 in single_interior_possible_values for c2 in single_interior_possible_values]\n",
    "    \n",
    "    single_tips_possible_values = ['A', 'C', 'G', 'U', '-']\n",
    "    paired_tips_possible_values = [c1 + c2 for c1 in single_tips_possible_values for c2 in single_tips_possible_values]\n",
    "    \n",
    "    __single_columns_probability, leaf_order = post_order_traversal(\n",
    "        tree, \n",
    "        tree.root, \n",
    "        single_interior_possible_values,\n",
    "        single_tips_possible_values, \n",
    "        single_rate_values,\n",
    "        input_sequences,\n",
    "        []\n",
    "    )\n",
    "    single_columns_probability = defaultdict(float)\n",
    "    for column in __single_columns_probability:\n",
    "        single_columns_probability[column] = sum(\n",
    "            __single_columns_probability[column][root] \n",
    "            * single_frequencies[root] for root in single_interior_possible_values\n",
    "        )\n",
    "    __single_columns_probability.clear()\n",
    "    \n",
    "    \n",
    "    __paired_columns_probability, _ = post_order_traversal(\n",
    "        tree, \n",
    "        tree.root, \n",
    "        paired_interior_possible_values, \n",
    "        paired_tips_possible_values,\n",
    "        paired_rate_values,\n",
    "        input_sequences,\n",
    "        [],\n",
    "    )\n",
    "    paired_columns_probability = defaultdict(float)\n",
    "    for column in __paired_columns_probability:\n",
    "        paired_columns_probability[column] = sum(\n",
    "            __paired_columns_probability[column][root] \n",
    "            * paired_frequencies[root] for root in paired_interior_possible_values\n",
    "        )\n",
    "    __paired_columns_probability.clear()\n",
    "\n",
    "\n",
    "    return single_columns_probability, paired_columns_probability, leaf_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pcfg(pcfg, filename):\n",
    "    unary_rules = pcfg.grammar.unary_rules\n",
    "    binary_rules = pcfg.grammar.binary_rules\n",
    "    \n",
    "    for A, B, C in binary_rules:\n",
    "        print(f\"{A} -> {B} {C} {pcfg.q[(A, B, C)]}\")\n",
    "            \n",
    "    for A, w in unary_rules:\n",
    "        print(f\"{A} -> {w} {pcfg.q[(A, w)]}\")\n",
    "    \n",
    "    with open(f\"{filename}.pcfg\", \"w+\") as pcfg_file:\n",
    "        for A, B, C in binary_rules:\n",
    "            pcfg_file.write(f\"{A} -> {B} {C} {pcfg.q[(A, B, C)]}\\n\")\n",
    "            \n",
    "        for A, w in unary_rules:\n",
    "            pcfg_file.write(f\"{A} -> {w} {pcfg.q[(A, w)]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_grammar(\n",
    "    columns,\n",
    "    pcfg,\n",
    "    single_column_probs, \n",
    "    paired_column_probs,\n",
    "    filename=\"Extended\"\n",
    "):\n",
    "    unary_rules = pcfg.grammar.unary_rules\n",
    "    binary_rules = pcfg.grammar.binary_rules\n",
    "    \n",
    "    with (open(f\"{filename}.pcfg\", \"w+\") as pcfg_file, open(f\"{filename}.cfg\", \"w+\") as cfg_file):\n",
    "        for A, B, C in binary_rules:\n",
    "            if A == \"$M\" and B == \"B\" and C == \"F\":\n",
    "                for column, prob in single_column_probs.items():\n",
    "                    if columns.get(column, False):\n",
    "                        term = str(column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A+term} -> B{term.lower()} F {pcfg.q[(A, B, C)]}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A+term} -> B{term.lower()} F\" + \"\\n\")\n",
    "            elif B == \"$M\" and C == \"E\":\n",
    "                for column, prob in paired_column_probs.items():\n",
    "                    left_column = tuple(\n",
    "                        pair[0] for pair in column if pair\n",
    "                    )\n",
    "                    right_column = tuple(\n",
    "                        pair[1] for pair in column if pair\n",
    "                    )\n",
    "                    if columns.get(left_column, False) and columns.get(right_column, False):\n",
    "                        left_term = str(left_column).replace(\" \", \"\")\n",
    "                        right_term = str(right_column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A} -> $M{left_term} E{right_term.lower()} {pcfg.q[(A, B, C)] * prob}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A} -> $M{left_term} E{right_term.lower()}\" + \"\\n\")\n",
    "            else:\n",
    "                pcfg_file.write(f\"{A} -> {B} {C} {pcfg.q[(A, B, C)]}\" + \"\\n\")\n",
    "                cfg_file.write(f\"{A} -> {B} {C}\" + \"\\n\")\n",
    "\n",
    "        for A, w in unary_rules:\n",
    "            if w == \"s\":\n",
    "                for column, prob in single_column_probs.items():\n",
    "                    if columns.get(column, False):\n",
    "                        term = str(column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A} -> {term} {pcfg.q[(A, w)] * prob}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A} -> {term}\" + \"\\n\")\n",
    "            elif w == \"d\":\n",
    "                for column, prob in single_column_probs.items():\n",
    "                    if columns.get(column, False):      \n",
    "                        term = str(column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A+term.lower()} -> {term} {pcfg.q[(A, w)]}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A+term.lower()} -> {term}\" + \"\\n\")\n",
    "            else:\n",
    "                pcfg_file.write(f\"{A} -> {w} {pcfg.q[(A, w)]}\" + \"\\n\")\n",
    "                cfg_file.write(f\"{A} -> {w}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_parse_tree(tree, table, start, end, non_terminal = \"S\", firstRun = True, layer=1):\n",
    "    if firstRun:\n",
    "        tree.add_node((start, end, \"S\"), layer=layer)\n",
    "        layer += 1\n",
    "        \n",
    "    if start == end and table[(start, end, non_terminal)]:\n",
    "        if non_terminal.startswith(\"B\"):\n",
    "            predicted_struct[start] = \"(\"\n",
    "        elif non_terminal.startswith(\"E\"):\n",
    "            predicted_struct[start] = \")\"\n",
    "        else:\n",
    "            predicted_struct[start] = \".\"\n",
    "\n",
    "    for _start, _end, _non_terminal in table[(start, end, non_terminal)]:\n",
    "        tree.add_node((_start, _end, _non_terminal), layer=layer)\n",
    "        new_layer = layer + 1\n",
    "        tree.add_edge((_start, _end, _non_terminal), (start, end, non_terminal))\n",
    "        gen_parse_tree(tree, table, _start, _end, _non_terminal, firstRun=False, layer=new_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_parse_tree(table, start_point, end_point, show=False):\n",
    "    parse_tree = nx.Graph()\n",
    "    \n",
    "    gen_parse_tree(parse_tree, table, start_point, end_point)\n",
    "    \n",
    "    if show:\n",
    "        pos = nx.multipartite_layout(parse_tree, subset_key =\"layer\")\n",
    "        nx.draw(\n",
    "            parse_tree, \n",
    "            pos, \n",
    "            # with_labels=True, \n",
    "            node_color='#74b9ff', \n",
    "            node_size=50, \n",
    "            font_size=10\n",
    "        )\n",
    "        nx.draw_networkx_nodes(\n",
    "            parse_tree, \n",
    "            pos, \n",
    "            nodelist=[(start_point, end_point, \"S\")], \n",
    "            node_color='#0984e3', \n",
    "            node_size=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Total Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_sequence(input_sequences, leaf_order):\n",
    "    total_sequence = \"\"\n",
    "    columns = defaultdict(bool)\n",
    "    for i in range(len(list(input_sequences.values())[0])):\n",
    "        column = tuple([\n",
    "            input_sequences[name][i] for name in leaf_order\n",
    "        ])\n",
    "        if column.count(\"<\") == len(leaf_order):\n",
    "            total_sequence += \"< \"\n",
    "        elif column.count(\">\") == len(leaf_order):\n",
    "            total_sequence += \"> \"\n",
    "        else:\n",
    "            columns[column] = True\n",
    "            total_sequence += str(column).replace(\" \", \"\") + \" \"\n",
    "    return total_sequence, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pairs(sequences, structure):\n",
    "    nopair_sequences = defaultdict(str)\n",
    "    nopair_sequences__ = defaultdict(str)\n",
    "    \n",
    "    for index, position in enumerate(structure):\n",
    "        for name in sequences.keys():\n",
    "            if is_pair_start(position):\n",
    "                a = list(nopair_sequences[name])\n",
    "                a.append(\"\")\n",
    "                nopair_sequences[name] = \"\".join(a)\n",
    "                \n",
    "                a = list(nopair_sequences__[name])\n",
    "                a.append(\"<\")\n",
    "                nopair_sequences__[name] = \"\".join(a)\n",
    "            elif is_pair_end(position):\n",
    "                a = list(nopair_sequences[name])\n",
    "                a.append(\"\")\n",
    "                nopair_sequences[name] = \"\".join(a)\n",
    "                \n",
    "                a = list(nopair_sequences__[name])\n",
    "                a.append(\">\")\n",
    "                nopair_sequences__[name] = \"\".join(a)\n",
    "            else:\n",
    "                a = list(nopair_sequences[name])\n",
    "                a.append(sequences[name][index])\n",
    "                nopair_sequences[name] = \"\".join(a)\n",
    "                \n",
    "                a = list(nopair_sequences__[name])\n",
    "                a.append(sequences[name][index])\n",
    "                nopair_sequences__[name] = \"\".join(a)\n",
    "\n",
    "    return nopair_sequences, nopair_sequences__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Primary Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_tree(\"./primaries/trees/RF00001.nwk\", \"RF00001\")\n",
    "open_tree(\"./primaries/trees/RF00005.nwk\", \"RF00005\")\n",
    "open_tree(\"./primaries/trees/RF00162.nwk\", \"RF00162\")\n",
    "# open_tree(\"./primaries/trees/RF01704.nwk\", \"RF01704\")\n",
    "# open_tree(\"./primaries/trees/RF01734.nwk\", \"RF01734\")\n",
    "# open_tree(\"./primaries/trees/RF01739.nwk\", \"RF01739\")\n",
    "# open_tree(\"./primaries/trees/RF02035.nwk\", \"RF02035\")\n",
    "# open_tree(\"./primaries/trees/RF02957.nwk\", \"RF02957\")\n",
    "# open_tree(\"./primaries/trees/RF03000.nwk\", \"RF03000\")\n",
    "# open_tree(\"./primaries/trees/RF03054.nwk\", \"RF03054\")\n",
    "# open_tree(\"./primaries/trees/RF03135.nwk\", \"RF03135\")\n",
    "\n",
    "read_sequences(\"./primaries/phylips/RF00001.phylip\", \"RF00001\")\n",
    "read_sequences(\"./primaries/phylips/RF00005.phylip\", \"RF00005\")\n",
    "read_sequences(\"./primaries/phylips/RF00162.phylip\", \"RF00162\")\n",
    "# read_sequences(\"./primaries/phylips/RF01704.phylip\", \"RF01704\")\n",
    "# read_sequences(\"./primaries/phylips/RF01734.phylip\", \"RF01734\")\n",
    "# read_sequences(\"./primaries/phylips/RF01739.phylip\", \"RF01739\")\n",
    "# read_sequences(\"./primaries/phylips/RF02035.phylip\", \"RF02035\")\n",
    "# read_sequences(\"./primaries/phylips/RF02957.phylip\", \"RF02957\")\n",
    "# read_sequences(\"./primaries/phylips/RF03000.phylip\", \"RF03000\")\n",
    "# read_sequences(\"./primaries/phylips/RF03054.phylip\", \"RF03054\")\n",
    "# read_sequences(\"./primaries/phylips/RF03135.phylip\", \"RF03135\")\n",
    "\n",
    "read_structure(\"./primaries/structures/RF00001.structure\", \"RF00001\")\n",
    "read_structure(\"./primaries/structures/RF00005.structure\", \"RF00005\")\n",
    "read_structure(\"./primaries/structures/RF00162.structure\", \"RF00162\")\n",
    "# read_structure(\"./primaries/structures/RF01704.structure\", \"RF01704\")\n",
    "# read_structure(\"./primaries/structures/RF01734.structure\", \"RF01734\")\n",
    "# read_structure(\"./primaries/structures/RF01739.structure\", \"RF01739\")\n",
    "# read_structure(\"./primaries/structures/RF02035.structure\", \"RF02035\")\n",
    "# read_structure(\"./primaries/structures/RF02957.structure\", \"RF02957\")\n",
    "# read_structure(\"./primaries/structures/RF03000.structure\", \"RF03000\")\n",
    "# read_structure(\"./primaries/structures/RF03054.structure\", \"RF03054\")\n",
    "# read_structure(\"./primaries/structures/RF03135.structure\", \"RF03135\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Evolutionary Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (single_frequencies, \n",
    "#  paired_frequencies, \n",
    "#  singles_prob, \n",
    "#  paireds_prob) = calc_frequencies(sequences, structures)\n",
    "\n",
    "# (single_rate_values,\n",
    "#  paired_rate_values) = calc_rate_values(\n",
    "#     trees,\n",
    "#     sequences, \n",
    "#     structures, \n",
    "#     single_frequencies, \n",
    "#     paired_frequencies, \n",
    "#     singles_prob, \n",
    "#     paireds_prob\n",
    "# )\n",
    "\n",
    "# # Save to a file\n",
    "# with open(\"./primaries/frequencies.pkl\", \"wb\") as file:\n",
    "#     pickle.dump((single_frequencies, \n",
    "#                  paired_frequencies, \n",
    "#                  singles_prob, \n",
    "#                  paireds_prob), file)\n",
    "\n",
    "# with open(\"./primaries/mutation_rate.pkl\", \"wb\") as file:\n",
    "#     pickle.dump((single_rate_values,\n",
    "#                  paired_rate_values), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from the file\n",
    "with open(\"./primaries/parameters/sRNA/frequencies.pkl\", \"rb\") as file:\n",
    "    (single_frequencies, \n",
    "     paired_frequencies, \n",
    "     singles_prob, \n",
    "     paireds_prob) = pickle.load(file)\n",
    "    \n",
    "with open(\"./primaries/parameters/sRNA/mutation_rate.pkl\", \"rb\") as file:\n",
    "    (single_rate_values,\n",
    "     paired_rate_values) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Grammar Of Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify_struct(structures, filename=\"./primaries/structures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train for first time\n",
    "# pcfg = PCNF(\"./primaries/structure.cfg\", \"./primaries/structure.pcfg\")\n",
    "# pcfg.estimate(\"./primaries/structures.train\", iter_num=5)\n",
    "# save_pcfg(pcfg, \"./primaries/structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from trained file\n",
    "pcfg = PCNF(\"./primaries/structure.cfg\", \"./primaries/parameters/sRNA/structure.pcfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {\n",
    "    \"RF01862\": [\n",
    "        {\n",
    "            \"Seq1\": \"ACGCCUUUGUCUAACACCCCGCACCGCGAGCACUAUUUCCCGGCGGGGUGAUUUCAGAGGGCGGAGAUUC\",\n",
    "            \"Seq2\": \"CCGUCUCUGUCUAACGCCUCACA-UGU---GCAGAAAUCGUUGUGGGGCGAUUUCAGGAGGCGGAGAUAU\",\n",
    "            \"Seq3\": \"ACGUCUCUGUCUAACGGGGUGCGGUGC---UGCUCUGUCGGCGCACCUCGAUUUCAGGAGACGGAGAUGA\",\n",
    "            \"Seq4\": \"ACGUCUCUGUCUAACGGGGUGCGACGC---UGCUCUGUCGGCGCACCUCGAUUUCAGGAGAUGGAGAUGA\",\n",
    "        },\n",
    "                    \".(((((((......(((((((((..................)))))))))......))))))).......\"\n",
    "    ],\n",
    "\n",
    "    \"RF01834\": [\n",
    "        {\n",
    "            \"Seq1\": \"GGGGCGAGCUGCAGCCCCAGUGAAUCAAAUGCAGC\",\n",
    "            \"Seq2\": \"GGGGCUAGCUGCAGCCCCAGUGAACCAAGUGCAGC\",\n",
    "            \"Seq3\": \"GGGGCGAGCUGCAGCCCCAGUGAAUCAAGUGCAGC\",\n",
    "            \"Seq4\": \"GGGGCGAGCUGCAGCCCCAGUAAACCAAGUGCAGC\",\n",
    "            \"Seq5\": \"GGGGCGAGCUGCAGCCCCGGUAAAUCAAGUGCAGC\",\n",
    "        },\n",
    "                    \"(((((..[[[[[[)))))...........]]]]]]\"\n",
    "    ],\n",
    "    \n",
    "    \"RF01077\": [\n",
    "        {\n",
    "            \"Seq1\": \"GUGUCUUGGAUCGCGCGGGUCAAAUGUAUAUGGUUCAUAUACAUCCGCAGGCACGUAAUAAA-GCGA\",\n",
    "            \"Seq2\": \"GUGUCUUGGAGCGCGCGGAGUAAACAUAUAUGGUUCAUAUAUGUCCGUAGGCACGUAAAAAAAGCGA\",\n",
    "            \"Seq3\": \"GUGUCUUGGUUCGCGCGGGUCAAGUGUAUAUGGUGCAUAUACAUCCGUAGGCACGUAAUAAA-GCGA\",\n",
    "            \"Seq4\": \"GUGUCUUGGAACGCGCGGGUCAAAUAUAAGUGGUUCACUUAUAUCCGUAGGCACGAAAAAUU-GCGU\",\n",
    "        },\n",
    "                    \"((((((....[[[[((((.....((((((((.....)))))))))))))))))).........]]]]\"\n",
    "    ],\n",
    "\n",
    "    \"RF01090\": [\n",
    "        {\n",
    "            \"Seq1\": \"GGGAAACUCCCAGGCCCCGCUGUAGAGGGACCGUCAGCGGCCGGGCCAG---AAAGAAUGAGGUCCCCA\",\n",
    "            \"Seq2\": \"GGGAAACUCCCUGGCCCCGCUGUAGAGGGACCCCCAGCGCCCGGGCCUG---AACCAGAAAGGUCCCCC\",\n",
    "            \"Seq3\": \"GGGAAACUCCCCGGCCCCGCUGUAGAGGGACCUUCAGCGACCGAACCAGCUUAGGCAAAAGAGUCCCCA\",\n",
    "            \"Seq4\": \"GGGAAACUCCCCGGCCCCGCUGUAGAGGGACCAUCAGCGACCGGGCCGG---AAAUCAUAAGGUCCCAA\",\n",
    "            \"Seq5\": \"GGGAAACUCCCCGGCCCCGCUGUAGGGGGACCUUCAGCGACAGGGCCAG---AACGAAUAAGGUCCCCA\",\n",
    "            \"Seq6\": \"GGGAAACUCCCCGGCCCCGCUGUAGAGGGACCUUCAGCGACCGGGCCAG---AAAUAAUAAGGUCCCCA\",\n",
    "            \"Seq7\": \"GGGAGACUCCCCGGCCCUGCUGUAGAGGGACCUUCAGCGACUGAGCCAG---AAAUAAUAAGGUCCCCA\",\n",
    "        },\n",
    "                    \"............((((((((((....[[[[[[[[)))))...)))))............]]]]]]]]..\"\n",
    "    ],\n",
    "    \n",
    "    \"RF01080\": [\n",
    "        {\n",
    "            \"Seq1\": \"GGUGCUUGCUAUUUCACCUAAAUCGAAAUAGC\",\n",
    "            \"Seq2\": \"GGUGCUUGUUAGUUCACCUAAAUCGAACUAAC\",\n",
    "            \"Seq3\": \"GGUGCUUUUAUGUUCACCGAAAUCGAACAUAC\",\n",
    "            \"Seq4\": \"GGUGCUUGUUAUUUCACCUAAAUCGAAAUAAC\",\n",
    "        },\n",
    "                    \"[[[[...(((((((]]]].......)))))))\"\n",
    "    ],\n",
    "    \n",
    "    \"RF01722\": [\n",
    "        {\n",
    "            \"Seq1\": \"ACUGCCGGGACUACGCCGGGCAAGGCCGGC-GCCGU-GCCGCGCUGUGACCCCGGCGGGGCGCCU\",\n",
    "            \"Seq2\": \"ACUGCCGGGACUACGCCGGAUAAGAGCGGC-UAUAU-GCCGCGCUGUGAAUCCGGCGGGGUUUUA\",\n",
    "            \"Seq3\": \"AAAUUCUAGAU--GGGCUACAGAGAGCCGC-UUAC--GCGGCACUGUGAUGUAGCCUGACGGUGU\",\n",
    "            \"Seq4\": \"ACG-CCGCGAC--GGGCUGUCGAGAGCCGC-GUCU--GCGGCGCUGUGAGACGGCCUGACGGCGU\",\n",
    "            \"Seq5\": \"UGUGCCGGGACUACGCCGGGUGAGAGCGGC-GUGU--GCCGCCCUGUGAAUCCGGCGGGGUGCCU\",\n",
    "            \"Seq6\": \"ACA-CAGCGAC--AGGCUGUUGAGAGCCGCCUCAGAGGCGGCGCUGUGAGACGGCCUGACGGUGU\",\n",
    "            \"Seq7\": \"AGCGCCGGGACUACGCCGGGUGAGAGCGGC-UGGC--GCCGCACUGUGGGCCCGGCGGGGUGCCU\",\n",
    "            \"Seq8\": \"ACAACCGCGAC--GGGCUGUGGAGAGCCGC-GCCC--GCGGCGCCGUGAAACAGCCUGACGGUGU\",\n",
    "        },\n",
    "                    \"..........(..((((((((....(((((.......))))).......))))))))........\"\n",
    "    ],\n",
    "    \n",
    "    \"RF03537\": [\n",
    "        {\n",
    "            \"Seq01\": \"CCCCUGCAUCAUGAUAAGGC-CGAACAUGGUGCAUGAAAGGGGAGG\",\n",
    "            \"Seq02\": \"CCCCCGCACCAUGACAAGGC-CGAACAUGGUGCACCAAAGGGGAGG\",\n",
    "            \"Seq03\": \"CCCCCGCCCCAUGACAAGGC-CGAACAUGGAGCAUUAAAGGG-AGG\",\n",
    "            \"Seq04\": \"CCCUUGCGUCCAGAGAAGGC-CGAACUGGGCGU---UAUAAGGAGG\",\n",
    "            \"Seq05\": \"CCCCCGCACCAUG-GAAGGC-CAAACAUGGUGCAUG-AAGGGAAAG\",\n",
    "            \"Seq06\": \"CAAAACCUCCCAGAGAAGGC-CGAACUGGGAGGCC-----AUGAAG\",\n",
    "            \"Seq07\": \"CAAAGCCUCCCAGAGAGGGC-CGAACUGGGAGGUU-----AUGAAG\",\n",
    "            \"Seq08\": \"CAAAAGGCCUCCUGGAAGGCUCACCAGGAGUUAGGCCAUUCUAGAG\",\n",
    "            \"Seq09\": \"CAAAAGGCCUCCUGGAAGGCUCACCAGGAGUUAGGCCGUUU--AGG\",\n",
    "            \"Seq10\": \"UGA---CCAUCCCUCAAGGCCGAGUGGGAUGCG------UAUGAAG\",\n",
    "        },\n",
    "                     \"((((.((((((((............))))))))......))))...\"\n",
    "    ],\n",
    "    \n",
    "    \"RF01737\":[\n",
    "        {\n",
    "            \"Seq1\": \"UCAUGUGACGAACAACCCGAAGGCUAAGGCCAGGGGA-GUUCUGAUGA\",\n",
    "            \"Seq2\": \"UCAUAUGACGAGCAACCCGAAGGUUUAGACCAGGGAA-GUUCUGAUGA\",\n",
    "            \"Seq3\": \"UCAGGUGACAAACGACCCGAAGGUAGAUACCAGGGGA-GUUUUGAUGA\",\n",
    "            \"Seq4\": \"CCGGAUGAUGGCCCGGGGGAACCCUAACGGGACCCCG-GGCCGGACGG\",\n",
    "            \"Seq5\": \"ACAGAUGAUGCACUAUCCGAAGGCUUA-GCCAGGGUAUGUGUUGAUGU\",\n",
    "            \"Seq6\": \"UCAUAUGACGAACAACCCGAAGGUUAAAACCAGGGAA-GUUCUGAUGA\",\n",
    "            \"Seq7\": \"UCAUAUGACGAGCAACCCGAAGGCUAAAGCCAGGGAA-GUUCUGAUGA\",\n",
    "            \"Seq8\": \"CCAGAUGAGGCACCACUCGAAGGC-AAUGCCAAAGUG-GUGCUGAUGG\",\n",
    "        },\n",
    "                    \"((((.....((((..(((...(((....))).)))...))))..))))\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = {\n",
    "    \"Seq01\": \"AGUG--UUUUUCUCUCCACUUAAAUCGAAGAGA\",\n",
    "    \"Seq02\": \"AGUG--UUUUUCCCUCCACUUAAAUCGAAGGGU\",\n",
    "    \"Seq03\": \"AGUG--UUUGCCGUUCCACUUAAAUCGAAACGG\",\n",
    "    \"Seq04\": \"AGUG--GCUAUCCCUCCACUUAAAUCGAAGGGU\",\n",
    "    \"Seq05\": \"AGUG--UUUCGGCUUCCACUUAAAUCGAAAGCC\",\n",
    "    \"Seq06\": \"AGUG--UUUUCAUGUCCACUUAAAUCGAACAUG\",\n",
    "    \"Seq07\": \"AGAG--UUUUUCCCUCCUCUUAAAUCGAAGGGC\",\n",
    "    \"Seq08\": \"AGUG--UUUUAUCCUCCACUUAAAUCGAAGGAU\",\n",
    "    \"Seq09\": \"AGUG--CUUUCCCGUUCACUUAAAUCGAACGGU\",\n",
    "    \"Seq10\": \"AGUG--UUUAUCCCUCCACUUAAAUCGAAGGGC\",\n",
    "    \"Seq11\": \"AGUG--CUUUCCAGUUCACUUAAAUAGAACUGG\",\n",
    "    \"Seq12\": \"AGUG--UUUUGAAGUCCACUUAAAUAGAACUUC\",\n",
    "    \"Seq13\": \"AGUG--UUUUUCUGUCCACUUAAAUCGAACAGA\",\n",
    "    \"Seq14\": \"AGUG--UUUUCGGCUCCACUUAAAUCGAAGCCC\",\n",
    "    \"Seq15\": \"AGUG--UUUUUCGUUCCACUUAAAUCGAAACGA\",\n",
    "    \"Seq16\": \"AGUG--UUUUCCUCUCCACUUAAAUCGAAGAGG\",\n",
    "    \"Seq17\": \"AGUG--UUUUUCUCUCCACUUGAAUCGAAGAGA\",\n",
    "    \"Seq18\": \"AGUG--UUUUUCCCUCCACUUAAAUCGAAGGGU\",\n",
    "    \"Seq19\": \"AGUG--UUUUUCCGUCCACUUAAAUCGAACGGC\",\n",
    "    \"Seq20\": \"AGAG--UUUUUCCCUCCUCUUAAAUCGAAGGGA\",\n",
    "    \"Seq21\": \"AGUG--UUUUUCUCUCCACUUAAAUCGAAGAG-\",\n",
    "    \"Seq22\": \"AGUG--UUUUUCCCUCCACUUAAAUCGAAGGAU\",\n",
    "    \"Seq23\": \"AGUG---UUUUCCCUCCACUUAAAUCGAAGGG-\",\n",
    "    \"Seq24\": \"AGUG---UUUACUCUCCACUUAAAUCGAAGAGU\",\n",
    "    \"Seq25\": \"AGUGUUUUUUUCCCUCCACUUAAAUCGAAGGGU\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_structure(input_sequences, single_frequencies, paired_frequencies, single_rate_values, paired_rate_values, pcfg, first_start_ratio, second_start_ratio, first_accelerat_ratio, second_accelerat_ratio, flag_ratio):    \n",
    "    # Step 1: Create the initial tree\n",
    "    estimated_tree = create_tree(input_sequences)\n",
    "\n",
    "    # Step 2: Calculate single and paired column probabilities\n",
    "    single_columns_probability, paired_columns_probability, leaf_order = get_columns_probability(\n",
    "        estimated_tree,\n",
    "        single_frequencies,\n",
    "        paired_frequencies,\n",
    "        single_rate_values,\n",
    "        paired_rate_values,\n",
    "        input_sequences,\n",
    "    )\n",
    "\n",
    "    # Step 3: Get the total sequence and columns based on leaf order\n",
    "    total_sequence, columns = get_total_sequence(input_sequences, leaf_order)\n",
    "\n",
    "    # Step 4: Extend the grammar\n",
    "    extend_grammar(\n",
    "        columns,\n",
    "        pcfg,\n",
    "        single_columns_probability,\n",
    "        paired_columns_probability,\n",
    "        filename=\"./outputs/Extended\"\n",
    "    )\n",
    "\n",
    "    # Step 5: Read from extended grammar file and run CYK algorithm\n",
    "    extended_pcfg = PCNF(\"./outputs/Extended.cfg\", \"./outputs/Extended.pcfg\")\n",
    "\n",
    "    prob, table = extended_pcfg.sentence_prob(total_sequence, first_start_ratio, first_accelerat_ratio)\n",
    "    # Step 6: Parse table to draw tree and generate structure\n",
    "    global predicted_struct\n",
    "    predicted_struct = {}\n",
    "    draw_parse_tree(table, 1, len(list(input_sequences.values())[0]))\n",
    "    structure = \"\".join(predicted_struct.values())\n",
    "\n",
    "    # Step 7: Remove pairs and regenerate sequences for second pass\n",
    "    _input_sequences, _input_sequences__ = remove_pairs(input_sequences, structure)\n",
    "    _total_sequence__, _columns = get_total_sequence(_input_sequences__, leaf_order)\n",
    "\n",
    "    # Step 8: Extend grammar again for second pass\n",
    "    extend_grammar(\n",
    "        _columns,\n",
    "        pcfg,\n",
    "        single_columns_probability,\n",
    "        paired_columns_probability,\n",
    "        filename=\"./outputs/Extended_\"\n",
    "    )\n",
    "\n",
    "    # Step 9: Read updated grammar and run flagged CYK algorithm\n",
    "    extended_pcfg = PCNF(\"./outputs/Extended_.cfg\", \"./outputs/Extended_.pcfg\")\n",
    "    prob, table = extended_pcfg.sentence_prob__(_total_sequence__, second_start_ratio, second_accelerat_ratio, flag_ratio)\n",
    "\n",
    "    # Step 10: Parse table to draw tree and generate second structure\n",
    "    predicted_struct = {}\n",
    "    draw_parse_tree(table, 1, len(list(_input_sequences.values())[0]))\n",
    "    _structure = \"\".join(predicted_struct.values())\n",
    "    \n",
    "    # Step 11: Combine structures for final result\n",
    "    __structure = \"\"\n",
    "    inner = 0\n",
    "    for index, char in enumerate(structure):\n",
    "        if char == \".\":\n",
    "            if _structure[inner] == \"(\":\n",
    "                __structure += \"[\"\n",
    "            elif _structure[inner] == \")\":\n",
    "                __structure += \"]\"\n",
    "            else:\n",
    "                __structure += \".\"\n",
    "            inner += 1\n",
    "        else:\n",
    "            __structure += structure[index]\n",
    "\n",
    "    return __structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[[[......(((((.]]]]........)))))'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_structure(input_sequences, single_frequencies, paired_frequencies, single_rate_values, paired_rate_values, pcfg, 1, 1, 1, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
