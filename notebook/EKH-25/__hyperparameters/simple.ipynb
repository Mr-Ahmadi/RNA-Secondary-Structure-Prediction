{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/aliahmadi/Documents/Projects/RNA-Secondary-Structure-Prediction/notebook/EKH-25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "from grammar.pcnf import PCNF\n",
    "from Bio import Phylo, SeqIO\n",
    "from copy import deepcopy\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "from math import log \n",
    "import numpy as np\n",
    "import shutil\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_struct = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairing Charecters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_start(pair_end):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return [val for val in pairing_chars if val[1] == pair_end][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pair_start(char):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return char in [p[0] for p in pairing_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pair_end(char):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return char in [p[1] for p in pairing_chars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(input_sequences, filename = \"./outputs/tree.nwk\", draw=False):\n",
    "  names = list(input_sequences.keys())\n",
    "  sequences = list(input_sequences.values())\n",
    "  \n",
    "  if len(names) <= 2:\n",
    "    return None\n",
    "  \n",
    "  os.mkdir(\"./tmp\")\n",
    "\n",
    "  if len(names) > 2:\n",
    "    phylip_file = \"./tmp/sequences.phylip\"\n",
    "    with open(phylip_file, \"w\") as f:\n",
    "      f.write(f\"{len(sequences)} {len(sequences[0])}\\n\\n\")\n",
    "      for i, seq in enumerate(sequences):\n",
    "        f.write(f\"{names[i]}\\t{seq}\\n\") \n",
    "    \n",
    "    # !./phyml -i tmp/sequences.phylip -m GTR\n",
    "    !./phyml -i tmp/sequences.phylip -m GTR > /dev/null 2>&1\n",
    "\n",
    "    \n",
    "    output_tree = Phylo.read(phylip_file + \"_phyml_tree.txt\", 'newick')\n",
    "\n",
    "    output_tree.root_at_midpoint()\n",
    "  \n",
    "  for index, clade in enumerate(output_tree.find_clades()):\n",
    "    if not clade.name:\n",
    "      clade.name = str(index)\n",
    "  \n",
    "  shutil.rmtree(\"./tmp\")\n",
    "  Phylo.write(output_tree, filename, \"newick\")\n",
    "  if draw:\n",
    "    Phylo.draw(output_tree)\n",
    "  \n",
    "  return output_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mutation Probablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutation_probablities(mutation_rate_values, time, order_array = [\"A\", \"C\", \"G\", \"U\"], gappy=False):\n",
    "    mutation_rate_matrix = np.zeros((len(order_array), len(order_array)), np.float64)\n",
    "    \n",
    "    for i_index, i_value in enumerate(order_array):\n",
    "        for j_index, j_value in enumerate(order_array):\n",
    "            mutation_rate_matrix[i_index,j_index] = mutation_rate_values[(i_value, j_value)]\n",
    "    \n",
    "    probability_rate_matrix = expm(mutation_rate_matrix * time)\n",
    "    \n",
    "    probability_rate_values = defaultdict(float)\n",
    "    for i_index, i_value in enumerate(order_array):\n",
    "        for j_index, j_value in enumerate(order_array):\n",
    "            probability_rate_values[(i_value, j_value)] = probability_rate_matrix[i_index,j_index]\n",
    "            \n",
    "    if gappy:      \n",
    "        if order_array == [\"A\", \"C\", \"G\", \"U\"]:\n",
    "            for i_index, i_value in enumerate(order_array):\n",
    "                for _, j_value in enumerate([\"-\"]):\n",
    "                    probability_rate_values[(i_value, j_value)] = 1\n",
    "        else:\n",
    "            for i_index, i_value in enumerate(order_array):\n",
    "                for j_index, j_value in enumerate(['A-', '-A', 'C-', '-C', 'G-', '-G', 'U-', '-U', '--']):\n",
    "                    if j_value == \"--\":\n",
    "                        probability_rate_values[(i_value, j_value)] = 1\n",
    "                    else:\n",
    "                        __probability = 0\n",
    "                        for nocleotid in [\"A\", \"C\", \"G\", \"U\"]:\n",
    "                            __j_value = j_value.replace('-', nocleotid)\n",
    "                            __probability += probability_rate_values[(i_value, __j_value)]\n",
    "                                \n",
    "                        probability_rate_values[(i_value, j_value)] = __probability\n",
    "    \n",
    "        \n",
    "    return probability_rate_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_needed(tuple1, tuple2):\n",
    "    return len(tuple1) == len(tuple2) and all(t1 == t2 for t1, t2 in zip(tuple1, tuple2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(input_sequences, leaf_order):\n",
    "    columns = defaultdict(list)\n",
    "    \n",
    "    for i in range(len(list(input_sequences.values())[0])):\n",
    "        column = tuple([\n",
    "            input_sequences[name][i] for name in leaf_order\n",
    "        ])\n",
    "        columns[column].append(i)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_column(input_sequences, column, leaf_order):\n",
    "    __leaf_order = leaf_order[-len(column):]\n",
    "    columns = get_columns(input_sequences, __leaf_order)\n",
    "    \n",
    "    if len(column[0]) == 1:\n",
    "        for _column, _places in columns.items():\n",
    "            if column_needed(column, _column):\n",
    "                return True\n",
    "    else:\n",
    "        for _column1, _places1 in columns.items():\n",
    "            left_column = tuple(\n",
    "                    pair[0] for pair in column if pair\n",
    "            )\n",
    "            if column_needed(left_column, _column1):\n",
    "                for _column2, _places2 in columns.items():\n",
    "                    right_column = tuple(\n",
    "                        pair[1] for pair in column if pair\n",
    "                    )\n",
    "                    if _places2 != [] and column_needed(right_column, _column2):\n",
    "                        if _places1[0] < _places2[-1]:\n",
    "                            return True\n",
    "    \n",
    "    return False       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Order Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_order_traversal(tree, current_node, interior_possible_values, tips_possible_values, rate_values, input_sequences, leaf_order = []): \n",
    "    current_columns_probability = defaultdict(lambda: defaultdict(float))\n",
    "    for child in current_node.clades:\n",
    "        # going to add a branch with a single nucleotide \n",
    "        if child.is_terminal():\n",
    "            leaf_order.append(child.name)\n",
    "            time = tree.distance(\n",
    "                current_node.name, \n",
    "                child.name\n",
    "            )\n",
    "            mutation_probablities = get_mutation_probablities(rate_values, time, interior_possible_values, True)\n",
    "            # have filled with some branch in last iteration\n",
    "            if current_columns_probability:\n",
    "                perv_columns_probability = deepcopy(current_columns_probability)\n",
    "                current_columns_probability.clear()\n",
    "                for left_column in perv_columns_probability:\n",
    "                    for child_value in tips_possible_values:\n",
    "                        if check_column(input_sequences, left_column + (child_value ,), leaf_order):\n",
    "                            for root in perv_columns_probability[left_column]:\n",
    "                                current_columns_probability[left_column + (child_value ,)][root] = (\n",
    "                                    mutation_probablities[(root, child_value)] * \n",
    "                                    perv_columns_probability[left_column][root]\n",
    "                                )\n",
    "                perv_columns_probability.clear()\n",
    "            \n",
    "            # haven't filled with any branch in last iteration\n",
    "            else:\n",
    "                # for mutation in mutation_probablities:\n",
    "                for child_value in tips_possible_values:\n",
    "                    if check_column(input_sequences, (child_value ,), leaf_order):\n",
    "                        for parent_value in interior_possible_values:\n",
    "                            current_columns_probability[(child_value ,)][parent_value] = mutation_probablities[(parent_value, child_value)]\n",
    "        # going to add a branch with a more than one nucleotide \n",
    "        else:    \n",
    "            inner_columns_probability, _ = post_order_traversal(tree, child, interior_possible_values, tips_possible_values, rate_values, input_sequences, leaf_order)\n",
    "            time = tree.distance(\n",
    "                current_node.name, \n",
    "                child.name\n",
    "            )\n",
    "            mutation_probablities = get_mutation_probablities(rate_values, time, interior_possible_values)\n",
    "            \n",
    "            # have filled with some branch in last iteration\n",
    "            if current_columns_probability:\n",
    "                perv_columns_probability = deepcopy(current_columns_probability)\n",
    "                current_columns_probability.clear()\n",
    "                \n",
    "                for left_column in perv_columns_probability:\n",
    "                    for right_column in inner_columns_probability:\n",
    "                        if check_column(input_sequences, left_column + right_column, leaf_order):\n",
    "                            for root in perv_columns_probability[left_column]:\n",
    "                                current_columns_probability[left_column + right_column][root] = sum(\n",
    "                                    (\n",
    "                                        mutation_probablities[(root, inner_root)] * \n",
    "                                        inner_columns_probability[right_column][inner_root] * \n",
    "                                        perv_columns_probability[left_column][root]\n",
    "                                    ) for inner_root in inner_columns_probability[right_column])\n",
    "                \n",
    "                perv_columns_probability.clear()\n",
    "\n",
    "            # haven't filled with some branch in last iteration\n",
    "            else:\n",
    "                for root_value in interior_possible_values:\n",
    "                    for column in inner_columns_probability:\n",
    "                        current_columns_probability[column][root_value] = sum(\n",
    "                            (\n",
    "                                mutation_probablities[(root_value, inner_root)] * \n",
    "                                inner_columns_probability[column][inner_root]\n",
    "                            ) for inner_root in inner_columns_probability[column]\n",
    "                        )\n",
    "                    \n",
    "    return current_columns_probability, leaf_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Columns Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_probability(\n",
    "    tree,  \n",
    "    single_frequencies, \n",
    "    paired_frequencies, \n",
    "    single_rate_values, \n",
    "    paired_rate_values,\n",
    "    input_sequences,\n",
    "):\n",
    "    single_interior_possible_values = ['A', 'C', 'G', 'U']\n",
    "    paired_interior_possible_values = [c1 + c2 for c1 in single_interior_possible_values for c2 in single_interior_possible_values]\n",
    "    \n",
    "    single_tips_possible_values = ['A', 'C', 'G', 'U', '-']\n",
    "    paired_tips_possible_values = [c1 + c2 for c1 in single_tips_possible_values for c2 in single_tips_possible_values]\n",
    "    \n",
    "    __single_columns_probability, leaf_order = post_order_traversal(\n",
    "        tree, \n",
    "        tree.root, \n",
    "        single_interior_possible_values,\n",
    "        single_tips_possible_values, \n",
    "        single_rate_values,\n",
    "        input_sequences,\n",
    "        []\n",
    "    )\n",
    "    single_columns_probability = defaultdict(float)\n",
    "    for column in __single_columns_probability:\n",
    "        single_columns_probability[column] = sum(\n",
    "            __single_columns_probability[column][root] \n",
    "            * single_frequencies[root] for root in single_interior_possible_values\n",
    "        )\n",
    "    __single_columns_probability.clear()\n",
    "    \n",
    "    \n",
    "    __paired_columns_probability, _ = post_order_traversal(\n",
    "        tree, \n",
    "        tree.root, \n",
    "        paired_interior_possible_values, \n",
    "        paired_tips_possible_values,\n",
    "        paired_rate_values,\n",
    "        input_sequences,\n",
    "        [],\n",
    "    )\n",
    "    paired_columns_probability = defaultdict(float)\n",
    "    for column in __paired_columns_probability:\n",
    "        paired_columns_probability[column] = sum(\n",
    "            __paired_columns_probability[column][root] \n",
    "            * paired_frequencies[root] for root in paired_interior_possible_values\n",
    "        )\n",
    "    __paired_columns_probability.clear()\n",
    "\n",
    "\n",
    "    return single_columns_probability, paired_columns_probability, leaf_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pcfg(pcfg, filename):\n",
    "    unary_rules = pcfg.grammar.unary_rules\n",
    "    binary_rules = pcfg.grammar.binary_rules\n",
    "    \n",
    "    for A, B, C in binary_rules:\n",
    "        print(f\"{A} -> {B} {C} {pcfg.q[(A, B, C)]}\")\n",
    "            \n",
    "    for A, w in unary_rules:\n",
    "        print(f\"{A} -> {w} {pcfg.q[(A, w)]}\")\n",
    "    \n",
    "    with open(f\"{filename}.pcfg\", \"w+\") as pcfg_file:\n",
    "        for A, B, C in binary_rules:\n",
    "            pcfg_file.write(f\"{A} -> {B} {C} {pcfg.q[(A, B, C)]}\\n\")\n",
    "            \n",
    "        for A, w in unary_rules:\n",
    "            pcfg_file.write(f\"{A} -> {w} {pcfg.q[(A, w)]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_grammar(\n",
    "    columns,\n",
    "    pcfg,\n",
    "    single_column_probs, \n",
    "    paired_column_probs,\n",
    "    filename=\"Extended\"\n",
    "):\n",
    "    unary_rules = pcfg.grammar.unary_rules\n",
    "    binary_rules = pcfg.grammar.binary_rules\n",
    "    \n",
    "    with (open(f\"{filename}.pcfg\", \"w+\") as pcfg_file, open(f\"{filename}.cfg\", \"w+\") as cfg_file):\n",
    "        for A, B, C in binary_rules:\n",
    "            if A == \"$M\" and B == \"B\" and C == \"F\":\n",
    "                for column, prob in single_column_probs.items():\n",
    "                    if columns.get(column, False):\n",
    "                        term = str(column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A+term} -> B{term.lower()} F {pcfg.q[(A, B, C)]}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A+term} -> B{term.lower()} F\" + \"\\n\")\n",
    "            elif B == \"$M\" and C == \"E\":\n",
    "                for column, prob in paired_column_probs.items():\n",
    "                    left_column = tuple(\n",
    "                        pair[0] for pair in column if pair\n",
    "                    )\n",
    "                    right_column = tuple(\n",
    "                        pair[1] for pair in column if pair\n",
    "                    )\n",
    "                    if columns.get(left_column, False) and columns.get(right_column, False):\n",
    "                        left_term = str(left_column).replace(\" \", \"\")\n",
    "                        right_term = str(right_column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A} -> $M{left_term} E{right_term.lower()} {pcfg.q[(A, B, C)] * prob}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A} -> $M{left_term} E{right_term.lower()}\" + \"\\n\")\n",
    "            else:\n",
    "                pcfg_file.write(f\"{A} -> {B} {C} {pcfg.q[(A, B, C)]}\" + \"\\n\")\n",
    "                cfg_file.write(f\"{A} -> {B} {C}\" + \"\\n\")\n",
    "\n",
    "        for A, w in unary_rules:\n",
    "            if w == \"s\":\n",
    "                for column, prob in single_column_probs.items():\n",
    "                    if columns.get(column, False):\n",
    "                        term = str(column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A} -> {term} {pcfg.q[(A, w)] * prob}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A} -> {term}\" + \"\\n\")\n",
    "            elif w == \"d\":\n",
    "                for column, prob in single_column_probs.items():\n",
    "                    if columns.get(column, False):      \n",
    "                        term = str(column).replace(\" \", \"\")\n",
    "                        pcfg_file.write(f\"{A+term.lower()} -> {term} {pcfg.q[(A, w)]}\" + \"\\n\")\n",
    "                        cfg_file.write(f\"{A+term.lower()} -> {term}\" + \"\\n\")\n",
    "            else:\n",
    "                pcfg_file.write(f\"{A} -> {w} {pcfg.q[(A, w)]}\" + \"\\n\")\n",
    "                cfg_file.write(f\"{A} -> {w}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_parse_tree(tree, table, start, end, non_terminal = \"S\", firstRun = True, layer=1):\n",
    "    if firstRun:\n",
    "        tree.add_node((start, end, \"S\"), layer=layer)\n",
    "        layer += 1\n",
    "        \n",
    "    if start == end and table[(start, end, non_terminal)]:\n",
    "        if non_terminal.startswith(\"B\"):\n",
    "            predicted_struct[start] = \"(\"\n",
    "        elif non_terminal.startswith(\"E\"):\n",
    "            predicted_struct[start] = \")\"\n",
    "        else:\n",
    "            predicted_struct[start] = \".\"\n",
    "\n",
    "    for _start, _end, _non_terminal in table[(start, end, non_terminal)]:\n",
    "        tree.add_node((_start, _end, _non_terminal), layer=layer)\n",
    "        new_layer = layer + 1\n",
    "        tree.add_edge((_start, _end, _non_terminal), (start, end, non_terminal))\n",
    "        gen_parse_tree(tree, table, _start, _end, _non_terminal, firstRun=False, layer=new_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_parse_tree(table, start_point, end_point, show=False):\n",
    "    parse_tree = nx.Graph()\n",
    "    \n",
    "    gen_parse_tree(parse_tree, table, start_point, end_point)\n",
    "    \n",
    "    if show:\n",
    "        pos = nx.multipartite_layout(parse_tree, subset_key =\"layer\")\n",
    "        nx.draw(\n",
    "            parse_tree, \n",
    "            pos, \n",
    "            # with_labels=True, \n",
    "            node_color='#74b9ff', \n",
    "            node_size=50, \n",
    "            font_size=10\n",
    "        )\n",
    "        nx.draw_networkx_nodes(\n",
    "            parse_tree, \n",
    "            pos, \n",
    "            nodelist=[(start_point, end_point, \"S\")], \n",
    "            node_color='#0984e3', \n",
    "            node_size=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Total Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_sequence(input_sequences, leaf_order):\n",
    "    total_sequence = \"\"\n",
    "    columns = defaultdict(bool)\n",
    "    for i in range(len(list(input_sequences.values())[0])):\n",
    "        column = tuple([\n",
    "            input_sequences[name][i] for name in leaf_order\n",
    "        ])\n",
    "        if column.count(\"<\") == len(leaf_order):\n",
    "            total_sequence += \"< \"\n",
    "        elif column.count(\">\") == len(leaf_order):\n",
    "            total_sequence += \"> \"\n",
    "        else:\n",
    "            columns[column] = True\n",
    "            total_sequence += str(column).replace(\" \", \"\") + \" \"\n",
    "    return total_sequence, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from the file\n",
    "with open(\"./primaries/parameters/_combined/frequencies.pkl\", \"rb\") as file:\n",
    "    (single_frequencies, \n",
    "     paired_frequencies, \n",
    "     singles_prob, \n",
    "     paireds_prob) = pickle.load(file)\n",
    "    \n",
    "with open(\"./primaries/parameters/_combined/mutation_rate.pkl\", \"rb\") as file:\n",
    "    (single_rate_values,\n",
    "     paired_rate_values) = pickle.load(file)\n",
    "    \n",
    "pcfg = PCNF(\"./primaries/structure.cfg\", \"./primaries/parameters/_combined/structure.pcfg\")\n",
    "\n",
    "_combined_params = (single_frequencies, paired_frequencies, single_rate_values, paired_rate_values, pcfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {\n",
    "    \"RF01862\": [\n",
    "        {\n",
    "            \"Seq1\": \"ACGCCUUUGUCUAACACCCCGCACCGCGAGCACUAUUUCCCGGCGGGGUGAUUUCAGAGGGCGGAGAUUC\",\n",
    "            \"Seq2\": \"CCGUCUCUGUCUAACGCCUCACA-UGU---GCAGAAAUCGUUGUGGGGCGAUUUCAGGAGGCGGAGAUAU\",\n",
    "            \"Seq3\": \"ACGUCUCUGUCUAACGGGGUGCGGUGC---UGCUCUGUCGGCGCACCUCGAUUUCAGGAGACGGAGAUGA\",\n",
    "            \"Seq4\": \"ACGUCUCUGUCUAACGGGGUGCGACGC---UGCUCUGUCGGCGCACCUCGAUUUCAGGAGAUGGAGAUGA\",\n",
    "        },\n",
    "                    \".(((((((......(((((((((..................)))))))))......))))))).......\"\n",
    "    ],\n",
    "    \n",
    "    \"RF01722\": [\n",
    "        {\n",
    "            \"Seq1\": \"ACUGCCGGGACUACGCCGGGCAAGGCCGGC-GCCGU-GCCGCGCUGUGACCCCGGCGGGGCGCCU\",\n",
    "            \"Seq2\": \"ACUGCCGGGACUACGCCGGAUAAGAGCGGC-UAUAU-GCCGCGCUGUGAAUCCGGCGGGGUUUUA\",\n",
    "            \"Seq3\": \"AAAUUCUAGAU--GGGCUACAGAGAGCCGC-UUAC--GCGGCACUGUGAUGUAGCCUGACGGUGU\",\n",
    "            \"Seq4\": \"ACG-CCGCGAC--GGGCUGUCGAGAGCCGC-GUCU--GCGGCGCUGUGAGACGGCCUGACGGCGU\",\n",
    "            \"Seq5\": \"UGUGCCGGGACUACGCCGGGUGAGAGCGGC-GUGU--GCCGCCCUGUGAAUCCGGCGGGGUGCCU\",\n",
    "            \"Seq6\": \"ACA-CAGCGAC--AGGCUGUUGAGAGCCGCCUCAGAGGCGGCGCUGUGAGACGGCCUGACGGUGU\",\n",
    "            \"Seq7\": \"AGCGCCGGGACUACGCCGGGUGAGAGCGGC-UGGC--GCCGCACUGUGGGCCCGGCGGGGUGCCU\",\n",
    "            \"Seq8\": \"ACAACCGCGAC--GGGCUGUGGAGAGCCGC-GCCC--GCGGCGCCGUGAAACAGCCUGACGGUGU\",\n",
    "        },\n",
    "                    \"..........(..((((((((....(((((.......))))).......))))))))........\"\n",
    "    ],\n",
    "    \n",
    "    \"RF03537\": [\n",
    "        {\n",
    "            \"Seq01\": \"CCCCUGCAUCAUGAUAAGGC-CGAACAUGGUGCAUGAAAGGGGAGG\",\n",
    "            \"Seq02\": \"CCCCCGCACCAUGACAAGGC-CGAACAUGGUGCACCAAAGGGGAGG\",\n",
    "            \"Seq03\": \"CCCCCGCCCCAUGACAAGGC-CGAACAUGGAGCAUUAAAGGG-AGG\",\n",
    "            \"Seq04\": \"CCCUUGCGUCCAGAGAAGGC-CGAACUGGGCGU---UAUAAGGAGG\",\n",
    "            \"Seq05\": \"CCCCCGCACCAUG-GAAGGC-CAAACAUGGUGCAUG-AAGGGAAAG\",\n",
    "            \"Seq06\": \"CAAAACCUCCCAGAGAAGGC-CGAACUGGGAGGCC-----AUGAAG\",\n",
    "            \"Seq07\": \"CAAAGCCUCCCAGAGAGGGC-CGAACUGGGAGGUU-----AUGAAG\",\n",
    "            \"Seq08\": \"CAAAAGGCCUCCUGGAAGGCUCACCAGGAGUUAGGCCAUUCUAGAG\",\n",
    "            \"Seq09\": \"CAAAAGGCCUCCUGGAAGGCUCACCAGGAGUUAGGCCGUUU--AGG\",\n",
    "            \"Seq10\": \"UGA---CCAUCCCUCAAGGCCGAGUGGGAUGCG------UAUGAAG\",\n",
    "        },\n",
    "                     \"((((.((((((((............))))))))......))))...\"\n",
    "    ],\n",
    "    \n",
    "    \"RF01737\":[\n",
    "        {\n",
    "            \"Seq1\": \"UCAUGUGACGAACAACCCGAAGGCUAAGGCCAGGGGA-GUUCUGAUGA\",\n",
    "            \"Seq2\": \"UCAUAUGACGAGCAACCCGAAGGUUUAGACCAGGGAA-GUUCUGAUGA\",\n",
    "            \"Seq3\": \"UCAGGUGACAAACGACCCGAAGGUAGAUACCAGGGGA-GUUUUGAUGA\",\n",
    "            \"Seq4\": \"CCGGAUGAUGGCCCGGGGGAACCCUAACGGGACCCCG-GGCCGGACGG\",\n",
    "            \"Seq5\": \"ACAGAUGAUGCACUAUCCGAAGGCUUA-GCCAGGGUAUGUGUUGAUGU\",\n",
    "            \"Seq6\": \"UCAUAUGACGAACAACCCGAAGGUUAAAACCAGGGAA-GUUCUGAUGA\",\n",
    "            \"Seq7\": \"UCAUAUGACGAGCAACCCGAAGGCUAAAGCCAGGGAA-GUUCUGAUGA\",\n",
    "            \"Seq8\": \"CCAGAUGAGGCACCACUCGAAGGC-AAUGCCAAAGUG-GUGCUGAUGG\",\n",
    "        },\n",
    "                    \"((((.....((((..(((...(((....))).)))...))))..))))\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_structure(input_sequences, single_frequencies, paired_frequencies, \n",
    "                      single_rate_values, paired_rate_values, pcfg, first_start_ratio, \n",
    "                      second_start_ratio, first_accelerat_ratio, second_accelerat_ratio, flag_ratio\n",
    "                     ):    \n",
    "    # Step 1: Create the initial tree\n",
    "    estimated_tree = create_tree(input_sequences)\n",
    "\n",
    "    # Step 2: Calculate single and paired column probabilities\n",
    "    single_columns_probability, paired_columns_probability, leaf_order = get_columns_probability(\n",
    "        estimated_tree,\n",
    "        single_frequencies,\n",
    "        paired_frequencies,\n",
    "        single_rate_values,\n",
    "        paired_rate_values,\n",
    "        input_sequences,\n",
    "    )\n",
    "\n",
    "    # Step 3: Get the total sequence and columns based on leaf order\n",
    "    total_sequence, columns = get_total_sequence(input_sequences, leaf_order)\n",
    "\n",
    "    # Step 4: Extend the grammar\n",
    "    extend_grammar(\n",
    "        columns,\n",
    "        pcfg,\n",
    "        single_columns_probability,\n",
    "        paired_columns_probability,\n",
    "        filename=\"./outputs/Extended\"\n",
    "    )\n",
    "\n",
    "    # Step 5: Read from extended grammar file and run CYK algorithm\n",
    "    extended_pcfg = PCNF(\"./outputs/Extended.cfg\", \"./outputs/Extended.pcfg\")\n",
    "\n",
    "    log_prob, table = extended_pcfg.sentence_prob(total_sequence, first_start_ratio, first_accelerat_ratio)\n",
    "    # Step 6: Parse table to draw tree and generate structure\n",
    "    global predicted_struct\n",
    "    predicted_struct = {}\n",
    "    draw_parse_tree(table, 1, len(list(input_sequences.values())[0]))\n",
    "    structure = \"\".join(predicted_struct.values())\n",
    "\n",
    "    return structure, log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dot_bracket(dot_bracket):\n",
    "    stack = {}\n",
    "    pairs = []\n",
    "    for i, char in enumerate(dot_bracket):\n",
    "        if char in \"([{<\":\n",
    "            stack[char] = stack.get(char, []) + [i]\n",
    "        elif char in \")]}>\":\n",
    "            if char in \"([{<)]}>\":  # Ensure char is a valid closing bracket\n",
    "                match_index = \"([{<)]}>\".index(char)\n",
    "                match = \"([{<\"[match_index - 4]  # Correct matching index logic\n",
    "                if stack.get(match):\n",
    "                    j = stack[match].pop()\n",
    "                    pairs.append((j, i))\n",
    "    return sorted(pairs)\n",
    "\n",
    "def check_structure(predicted_structure, original_structure):\n",
    "    predicted_pairs = set(parse_dot_bracket(predicted_structure))\n",
    "    original_pairs = set(parse_dot_bracket(original_structure))\n",
    "\n",
    "    true_positives_pairs = len(predicted_pairs & original_pairs)\n",
    "    false_positives_pairs = len(predicted_pairs - original_pairs)\n",
    "    false_negatives_pairs = len(original_pairs - predicted_pairs)\n",
    "\n",
    "    total_positions = len(predicted_structure)\n",
    "    predicted_unpaired = set(i for i in range(total_positions) if all(i not in pair for pair in predicted_pairs))\n",
    "    original_unpaired  = set(i for i in range(total_positions) if all(i not in pair for pair in original_pairs))\n",
    "    \n",
    "    predicted_unpaired = set(i for i in range(total_positions) if all(i not in pair for pair in predicted_pairs))\n",
    "    original_unpaired  = set(i for i in range(total_positions) if all(i not in pair for pair in original_pairs))\n",
    "    \n",
    "    true_positives_unpairs = len(predicted_unpaired & original_unpaired)\n",
    "    false_positives_unpairs = len(predicted_unpaired - original_unpaired)\n",
    "    false_negatives_unpairs= len(original_unpaired - predicted_unpaired)\n",
    "    \n",
    "    # Calculate weights for paired and unpaired\n",
    "    paired_weight = len(original_pairs) * 2\n",
    "    unpaired_weight = len(original_unpaired)\n",
    "\n",
    "    return (true_positives_pairs, \n",
    "            false_positives_pairs, \n",
    "            false_negatives_pairs, \n",
    "            true_positives_unpairs, \n",
    "            false_positives_unpairs, \n",
    "            false_negatives_unpairs, \n",
    "            paired_weight, unpaired_weight)\n",
    "\n",
    "\n",
    "def calc_f1_score(true_positives, false_positives, false_negatives):\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    return f1_score\n",
    "\n",
    "def calc_weighted_mean_f1_score(first_weight, first_f1, second_weight, second_f1):\n",
    "    return ((first_weight * first_f1 + second_weight * second_f1) / (first_weight + second_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_individual(individual, test_data):\n",
    "    _true_positives_pairs, _false_positives_pairs, _false_negatives_pairs = 0, 0, 0\n",
    "    _true_positives_unpairs, _false_positives_unpairs, _false_negatives_unpairs = 0, 0, 0\n",
    "    _paired_weight, _unpaired_weight = 0, 0\n",
    "\n",
    "    for test_name, (alignment, actual_structure) in test_data.items():\n",
    "        predicted_structure, _ = predict_structure(alignment, *_combined_params, *individual)\n",
    "        \n",
    "        (true_positives_pairs, \n",
    "        false_positives_pairs, \n",
    "        false_negatives_pairs, \n",
    "        true_positives_unpairs, \n",
    "        false_positives_unpairs, \n",
    "        false_negatives_unpairs, \n",
    "        paired_weight, unpaired_weight) = check_structure(predicted_structure, actual_structure)\n",
    "\n",
    "        _true_positives_pairs += true_positives_pairs\n",
    "        _false_positives_pairs += false_positives_pairs\n",
    "        _false_negatives_pairs += false_negatives_pairs\n",
    "        _true_positives_unpairs += true_positives_unpairs\n",
    "        _false_positives_unpairs += false_positives_unpairs\n",
    "        _false_negatives_unpairs += false_negatives_unpairs\n",
    "        _paired_weight += paired_weight\n",
    "        _unpaired_weight += unpaired_weight\n",
    "\n",
    "    paired_f1_score = calc_f1_score(_true_positives_pairs, _false_positives_pairs, _false_negatives_pairs)\n",
    "    unpaired_f1_score = calc_f1_score(_true_positives_unpairs, _false_positives_unpairs, _false_negatives_unpairs)\n",
    "\n",
    "    mean_f1_score = calc_weighted_mean_f1_score(_unpaired_weight, unpaired_f1_score, _paired_weight, paired_f1_score)\n",
    "    return mean_f1_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
