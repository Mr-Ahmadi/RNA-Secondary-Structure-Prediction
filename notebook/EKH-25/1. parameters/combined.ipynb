{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/aliahmadi/Documents/Projects/RNA-Secondary-Structure-Prediction/notebook/EKH-25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.linalg import expm\n",
    "from grammar.pcnf import PCNF\n",
    "from Bio import Phylo, SeqIO\n",
    "from copy import deepcopy\n",
    "from io import StringIO\n",
    "import networkx as nx\n",
    "from math import log \n",
    "import numpy as np\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IUPAC Nucleotide table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iupac_nucleotides = {\n",
    "    'A':[\"A\"],\n",
    "    'C':[\"C\"],\n",
    "    'G':[\"G\"],\n",
    "    'U':[\"U\"], \n",
    "    'R':[\"A\", \"G\"], \n",
    "    'Y':[\"C\", \"U\"],\n",
    "    'S':[\"G\", \"C\"],\n",
    "    'W':[\"A\", \"U\"],\n",
    "    'K':[\"G\", \"U\"],\n",
    "    'M':[\"A\", \"C\"],\n",
    "    'B':[\"C\", \"G\", \"U\"],\n",
    "    'D':[\"A\", \"G\", \"U\"],\n",
    "    'H':[\"A\", \"C\", \"U\"],\n",
    "    'V':[\"A\", \"C\", \"G\"],\n",
    "    'N':[\"A\", \"C\", \"G\", \"U\"],\n",
    "    '-': [\"-\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = defaultdict(lambda: Phylo.read(StringIO(\"();\"), \"newick\"))\n",
    "sequences = defaultdict(lambda: defaultdict(str))\n",
    "structures = defaultdict(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairing Charecters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_start(pair_end):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return [val for val in pairing_chars if val[1] == pair_end][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pair_start(char):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return char in [p[0] for p in pairing_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pair_end(char):\n",
    "    pairing_chars = [(\"<\", \">\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\")]\n",
    "    return char in [p[1] for p in pairing_chars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_str(input_string, valid_characters = ['A','C', 'G', 'U']):\n",
    "    for char in input_string:\n",
    "        if char not in valid_characters:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clade_names_fix(tree):\n",
    "    for index, clade in enumerate(tree.find_clades()):\n",
    "        if not clade.name:\n",
    "            clade.name = str(index)\n",
    "\n",
    "def read_tree(filename: str):\n",
    "    Tree = Phylo.read(filename, 'newick')\n",
    "    clade_names_fix(Tree)\n",
    "    return Tree\n",
    "\n",
    "def open_tree(filename: str, dataset_name):\n",
    "    Tree = Phylo.read(filename, 'newick')\n",
    "    clade_names_fix(Tree)\n",
    "    \n",
    "    trees[dataset_name] = Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sequences (filename: str, dataset_name):\n",
    "    dataset = defaultdict(str)\n",
    "    \n",
    "    with open(filename) as file:\n",
    "        records = SeqIO.parse(file, \"phylip-relaxed\")\n",
    "        count = 0\n",
    "        \n",
    "        for record in records:\n",
    "            dataset[record.id] = record.seq\n",
    "            count += 1\n",
    "           \n",
    "        dataset[\"_weight\"] = 1000 / count   \n",
    "        \n",
    "    sequences[dataset_name] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_structure(filename: str, dataset_name):\n",
    "    with open(filename) as file:\n",
    "        structures[dataset_name] = file.readline().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_struct(structures, filename=\"./primaries/structures\"):\n",
    "    pairing_chars = [\"<\", \">\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    simplified = \"\"\n",
    "    for _, structure in structures.items():\n",
    "        for i in range(len(structure)):\n",
    "            if structure[i] in pairing_chars:\n",
    "                simplified += \"d \"\n",
    "            else:\n",
    "                simplified += \"s \"\n",
    "        simplified += \"\\n\"\n",
    "    \n",
    "    simplified = simplified.rstrip('\\n')\n",
    "    \n",
    "    if filename != \"\":        \n",
    "        with open(f\"{filename}.train\", \"w+\") as file:\n",
    "            file.write(simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(input_sequences, filename = \"./outputs/tree.nwk\", draw=True):\n",
    "  names = list(input_sequences.keys())\n",
    "  sequences = list(input_sequences.values())\n",
    "  \n",
    "  if len(names) <= 2:\n",
    "    return None\n",
    "  \n",
    "  os.mkdir(\"./tmp\")\n",
    "\n",
    "  if len(names) > 2:\n",
    "    phylip_file = \"./tmp/sequences.phylip\"\n",
    "    with open(phylip_file, \"w\") as f:\n",
    "      f.write(f\"{len(sequences)} {len(sequences[0])}\\n\\n\")\n",
    "      for i, seq in enumerate(sequences):\n",
    "        f.write(f\"{names[i]}\\t{seq}\\n\") \n",
    "    \n",
    "    !./phyml -i tmp/sequences.phylip -m GTR\n",
    "    \n",
    "    output_tree = Phylo.read(phylip_file + \"_phyml_tree.txt\", 'newick')\n",
    "\n",
    "    output_tree.root_at_midpoint()\n",
    "  \n",
    "  for index, clade in enumerate(output_tree.find_clades()):\n",
    "    if not clade.name:\n",
    "      clade.name = str(index)\n",
    "  \n",
    "  shutil.rmtree(\"./tmp\")\n",
    "  Phylo.write(output_tree, filename, \"newick\")\n",
    "  \n",
    "  Phylo.draw(output_tree)\n",
    "  \n",
    "  return output_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_frequencies (sequences, structures):\n",
    "    single_nucleotides = defaultdict(int)\n",
    "    paired_nucleotides = defaultdict(int)\n",
    "    \n",
    "    total_singles = 0\n",
    "    total_paireds = 0\n",
    "    \n",
    "    # Stack of unpaired nucleotides (structure symbol, nocleotide)\n",
    "    unpaired_nucleotides = []\n",
    "    for dataset_name, dataset_values in sequences.items():\n",
    "        sequences_weight = dataset_values[\"_weight\"]\n",
    "        dataset_sequences = [v for k, v in dataset_values.items() if k != \"_weight\"]\n",
    "        dataset_structure = structures[dataset_name]\n",
    "        for sequence in dataset_sequences:\n",
    "            for index, nucleotide in enumerate(sequence): \n",
    "                structure_symbol = dataset_structure[index]\n",
    "                # Having a charecter [ '(', '[', '{', '<' ]\n",
    "                if is_pair_start(structure_symbol):\n",
    "                    unpaired_nucleotides.append((structure_symbol, iupac_nucleotides[nucleotide]))\n",
    "                # Having a charecter [ ')', ']', '}', '>' ]\n",
    "                elif is_pair_end(structure_symbol):\n",
    "                    unpaired_nucleotide = unpaired_nucleotides.pop()\n",
    "                    if unpaired_nucleotide[0] == get_pair_start(structure_symbol):\n",
    "                        targets = [f\"{nucl1}{nucl2}\" \n",
    "                            for nucl1 in unpaired_nucleotide[1] \n",
    "                            for nucl2 in iupac_nucleotides[nucleotide]\n",
    "                        ]\n",
    "                        for target in targets:\n",
    "                            if is_valid_str(target):\n",
    "                                # print(len(targets))\n",
    "                                paired_nucleotides[target] += sequences_weight / len(targets)\n",
    "                                paired_nucleotides[target[::-1]] += sequences_weight / len(targets)\n",
    "                                \n",
    "                                total_paireds += sequences_weight / len(targets)\n",
    "                    else:\n",
    "                        raise ValueError('Invalid pattern in structure')\n",
    "                # Having a non-pairing charecter\n",
    "                else:\n",
    "                    targets = iupac_nucleotides[nucleotide]\n",
    "                    for target in targets:\n",
    "                        if is_valid_str(nucleotide):\n",
    "                            # print(len(targets))\n",
    "                            single_nucleotides[target] += sequences_weight / len(targets)\n",
    "                            \n",
    "                            total_singles += sequences_weight / len(targets)\n",
    "\n",
    "    total = total_singles + (total_paireds * 2)\n",
    "                \n",
    "    for key, value in single_nucleotides.items():\n",
    "        single_nucleotides[key] = value / total_singles\n",
    "    for key, value in paired_nucleotides.items():\n",
    "        paired_nucleotides[key] = value / (total_paireds * 2)\n",
    "        \n",
    "    return (\n",
    "        single_nucleotides,\n",
    "        paired_nucleotides,\n",
    "        total_singles / total,\n",
    "        (total_paireds * 2) / total\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check simularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_simularity(seq1:str, seq2:str):\n",
    "    simularity = 0\n",
    "    if len(seq1) == len(seq2):\n",
    "        for i in range(len(seq1)):\n",
    "            if seq1[i] == seq2[i]:\n",
    "                simularity += 1\n",
    "        return simularity / len(seq1) >= .85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(seq1: str, seq2: str) -> bool:\n",
    "    # Validate input\n",
    "    if len(seq1) != len(seq2):\n",
    "        return False  # Sequences must be of the same length\n",
    "\n",
    "    # Define nucleotide groups\n",
    "    pyrimidines = {'C', 'U'}  # Cytosine, Uracil\n",
    "    purines = {'A', 'G'}      # Adenine, Guanine\n",
    "\n",
    "    # Initialize similarity count\n",
    "    similarity = 0\n",
    "\n",
    "    for i in range(len(seq1)):\n",
    "        # Handle IUPAC codes\n",
    "        possible_nucleotides1 = iupac_nucleotides.get(seq1[i], [seq1[i]])\n",
    "        possible_nucleotides2 = iupac_nucleotides.get(seq2[i], [seq2[i]])\n",
    "        \n",
    "        match_score = 0\n",
    "        for n1 in possible_nucleotides1:\n",
    "            for n2 in possible_nucleotides2:\n",
    "                if n1 == n2:\n",
    "                    match_score += 1 / (len(possible_nucleotides1) * len(possible_nucleotides2))\n",
    "                elif (n1 in pyrimidines and n2 in pyrimidines) or (n1 in purines and n2 in purines):\n",
    "                    match_score += 0.5 / (len(possible_nucleotides1) * len(possible_nucleotides2))                    \n",
    "        \n",
    "        similarity += match_score \n",
    "\n",
    "    # Calculate final similarity ratio\n",
    "    similarity_ratio = similarity / len(seq1)\n",
    "\n",
    "    return similarity_ratio >= 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Rate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rate_values(\n",
    "    trees,\n",
    "    sequences: defaultdict, \n",
    "    structures, \n",
    "    single_frequencies, \n",
    "    paired_frequencies, \n",
    "    singles_prob, \n",
    "    paireds_prob\n",
    "):\n",
    "    unpaired_nucleotides = []\n",
    "    \n",
    "    single_mutation_count = defaultdict(float)\n",
    "    paired_mutation_count = defaultdict(float)\n",
    "    k_value = 0\n",
    "    \n",
    "    for dataset_name, dataset_values in sequences.items():\n",
    "        sequences_weight = dataset_values[\"_weight\"]\n",
    "        dataset_sequences = [(k, v) for k, v in dataset_values.items() if k != \"_weight\"]\n",
    "        dataset_structure = structures[dataset_name]\n",
    "        \n",
    "        for i in range(len(dataset_sequences)):\n",
    "            temp_single_mutation_count = defaultdict(int)\n",
    "            temp_paired_mutation_count = defaultdict(int)\n",
    "            k_temp = 0\n",
    "            \n",
    "            same_first_sequence_count = 0\n",
    "            \n",
    "            for j in range(len(dataset_sequences)):\n",
    "                columns_count = 0\n",
    "                \n",
    "                first_name = dataset_sequences[i][0]\n",
    "                second_name = dataset_sequences[j][0]\n",
    "                first_sequence = dataset_sequences[i][1]\n",
    "                second_sequence = dataset_sequences[j][1]\n",
    "                # The pair should contain diffrent \n",
    "                # sequence with at least %85 simularity.\n",
    "                if i != j and check_simularity(first_sequence, second_sequence):\n",
    "                    same_first_sequence_count += 1\n",
    "                    for k in range(len(first_sequence)): \n",
    "                        structure_symbol = dataset_structure[k]\n",
    "                        # Having a charecter [ '(', '[', '{', '<' ]\n",
    "                        if is_pair_start(structure_symbol):\n",
    "                            unpaired_nucleotides.append((\n",
    "                                structure_symbol, \n",
    "                                iupac_nucleotides[first_sequence[k]],\n",
    "                                iupac_nucleotides[second_sequence[k]]\n",
    "                            ))\n",
    "                        # Having a charecter [ ')', ']', '}', '>' ]\n",
    "                        elif is_pair_end(structure_symbol):\n",
    "                            unpaired_nucleotide = unpaired_nucleotides.pop()\n",
    "                            \n",
    "                            first_side_targets = [f\"{nucl1}{nucl2}\" \n",
    "                                for nucl1 in unpaired_nucleotide[1] \n",
    "                                for nucl2 in iupac_nucleotides[first_sequence[k]]\n",
    "                            ]\n",
    "                            second_side_targets = [f\"{nucl1}{nucl2}\" \n",
    "                                for nucl1 in unpaired_nucleotide[2] \n",
    "                                for nucl2 in iupac_nucleotides[second_sequence[k]]\n",
    "                            ]\n",
    "                            \n",
    "                            if unpaired_nucleotide[0] == get_pair_start(structure_symbol):\n",
    "                                for first_side in first_side_targets:\n",
    "                                    for second_side in second_side_targets:\n",
    "                                        if (is_valid_str(first_side) \n",
    "                                        and is_valid_str(second_side)):\n",
    "                                            columns_count += (2 * sequences_weight) / (len(first_side_targets) * len(second_side_targets))\n",
    "                                            \n",
    "                                            if first_side != second_side:\n",
    "                                                temp_paired_mutation_count[\n",
    "                                                    (first_side, second_side)\n",
    "                                                ] += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                                                temp_paired_mutation_count[\n",
    "                                                    (first_side[::-1], second_side[::-1])\n",
    "                                                ] += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                            else:\n",
    "                                raise ValueError('Invalid pattern in structure')    \n",
    "                        # Having a non-pairing charecter\n",
    "                        else:\n",
    "                            first_side_targets = iupac_nucleotides[first_sequence[k]]\n",
    "                            second_side_targets = iupac_nucleotides[second_sequence[k]]\n",
    "                            \n",
    "                            for first_side in first_side_targets:\n",
    "                                for second_side in second_side_targets:\n",
    "                                    if (is_valid_str(first_side) \n",
    "                                    and is_valid_str(second_side)):\n",
    "                                        columns_count += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                                        if first_side != second_side:\n",
    "                                            temp_single_mutation_count[(\n",
    "                                                first_side, \n",
    "                                                second_side,\n",
    "                                            )] += sequences_weight / (len(first_side_targets) * len(second_side_targets))\n",
    "                    \n",
    "                    k_temp += (trees[dataset_name].distance(\n",
    "                        first_name, \n",
    "                        second_name\n",
    "                    ) * columns_count)\n",
    "                    \n",
    "            \n",
    "            if same_first_sequence_count > 0:\n",
    "                k_value += (k_temp / same_first_sequence_count)\n",
    "                \n",
    "                for key in temp_single_mutation_count:\n",
    "                    single_mutation_count[key] += (temp_single_mutation_count[key] \n",
    "                                                / same_first_sequence_count)\n",
    "                for key in temp_paired_mutation_count:\n",
    "                    paired_mutation_count[key] += (temp_paired_mutation_count[key] \n",
    "                                                / same_first_sequence_count)\n",
    "                \n",
    "    single_chars = [\"A\", \"C\", \"G\", \"U\"]\n",
    "    paired_chars = [c1 + c2 for c1 in single_chars for c2 in single_chars]\n",
    "    \n",
    "    single_rate_values = defaultdict(float)\n",
    "    paired_rate_values = defaultdict(float)\n",
    "            \n",
    "    for i in single_chars:\n",
    "        single_rate_values[(i,i)] = 0\n",
    "        for j in single_chars:\n",
    "            if i != j:\n",
    "                single_rate_values[(i,j)] = (single_mutation_count[(i,j)] \n",
    "                                             / (singles_prob * single_frequencies[i] * k_value))\n",
    "                single_rate_values[(i,i)] = single_rate_values[(i,i)] - single_rate_values[(i,j)]\n",
    "\n",
    "    for i in paired_chars:\n",
    "        paired_rate_values[(i,i)] = 0\n",
    "        for j in paired_chars:\n",
    "            if i != j:\n",
    "                paired_rate_values[(i,j)] = ((paired_mutation_count[(i,j)] * 2)\n",
    "                                             / (paireds_prob * paired_frequencies[i] * k_value))\n",
    "                paired_rate_values[(i,i)] = paired_rate_values[(i,i)] - paired_rate_values[(i,j)]\n",
    "    \n",
    "    return single_rate_values, paired_rate_values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pcfg(pcfg, filename):\n",
    "    unary_rules = pcfg.grammar.unary_rules\n",
    "    binary_rules = pcfg.grammar.binary_rules\n",
    "    \n",
    "    with open(f\"{filename}.pcfg\", \"w+\") as pcfg_file:\n",
    "        for A, B, C in binary_rules:\n",
    "            pcfg_file.write(f\"{A} -> {B} {C} {pcfg.q[(A, B, C)]}\\n\")\n",
    "            \n",
    "        for A, w in unary_rules:\n",
    "            pcfg_file.write(f\"{A} -> {w} {pcfg.q[(A, w)]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Primary Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_tree(\"./primaries/trees/RF00001.nwk\", \"RF00001\")\n",
    "open_tree(\"./primaries/trees/RF00005.nwk\", \"RF00005\")\n",
    "# open_tree(\"./primaries/trees/RF00162.nwk\", \"RF00162\")\n",
    "# open_tree(\"./primaries/trees/RF01704.nwk\", \"RF01704\")\n",
    "# open_tree(\"./primaries/trees/RF01734.nwk\", \"RF01734\")\n",
    "# open_tree(\"./primaries/trees/RF01739.nwk\", \"RF01739\")\n",
    "# open_tree(\"./primaries/trees/RF02035.nwk\", \"RF02035\")\n",
    "# open_tree(\"./primaries/trees/RF02957.nwk\", \"RF02957\")\n",
    "open_tree(\"./primaries/trees/RF03000.nwk\", \"RF03000\")\n",
    "# open_tree(\"./primaries/trees/RF03054.nwk\", \"RF03054\")\n",
    "# open_tree(\"./primaries/trees/RF03135.nwk\", \"RF03135\")\n",
    "\n",
    "read_sequences(\"./primaries/phylips/RF00001.phylip\", \"RF00001\")\n",
    "read_sequences(\"./primaries/phylips/RF00005.phylip\", \"RF00005\")\n",
    "# read_sequences(\"./primaries/phylips/RF00162.phylip\", \"RF00162\")\n",
    "# read_sequences(\"./primaries/phylips/RF01704.phylip\", \"RF01704\")\n",
    "# read_sequences(\"./primaries/phylips/RF01734.phylip\", \"RF01734\")\n",
    "# read_sequences(\"./primaries/phylips/RF01739.phylip\", \"RF01739\")\n",
    "# read_sequences(\"./primaries/phylips/RF02035.phylip\", \"RF02035\")\n",
    "# read_sequences(\"./primaries/phylips/RF02957.phylip\", \"RF02957\")\n",
    "read_sequences(\"./primaries/phylips/RF03000.phylip\", \"RF03000\")\n",
    "# read_sequences(\"./primaries/phylips/RF03054.phylip\", \"RF03054\")\n",
    "# read_sequences(\"./primaries/phylips/RF03135.phylip\", \"RF03135\")\n",
    "\n",
    "read_structure(\"./primaries/structures/RF00001.structure\", \"RF00001\")\n",
    "read_structure(\"./primaries/structures/RF00005.structure\", \"RF00005\")\n",
    "# read_structure(\"./primaries/structures/RF00162.structure\", \"RF00162\")\n",
    "# read_structure(\"./primaries/structures/RF01704.structure\", \"RF01704\")\n",
    "# read_structure(\"./primaries/structures/RF01734.structure\", \"RF01734\")\n",
    "# read_structure(\"./primaries/structures/RF01739.structure\", \"RF01739\")\n",
    "# read_structure(\"./primaries/structures/RF02035.structure\", \"RF02035\")\n",
    "# read_structure(\"./primaries/structures/RF02957.structure\", \"RF02957\")\n",
    "read_structure(\"./primaries/structures/RF03000.structure\", \"RF03000\")\n",
    "# read_structure(\"./primaries/structures/RF03054.structure\", \"RF03054\")\n",
    "# read_structure(\"./primaries/structures/RF03135.structure\", \"RF03135\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Evolutionary Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(single_frequencies, \n",
    " paired_frequencies, \n",
    " singles_prob, \n",
    " paireds_prob) = calc_frequencies(sequences, structures)\n",
    "\n",
    "(single_rate_values,\n",
    " paired_rate_values) = calc_rate_values(\n",
    "    trees,\n",
    "    sequences, \n",
    "    structures, \n",
    "    single_frequencies, \n",
    "    paired_frequencies, \n",
    "    singles_prob, \n",
    "    paireds_prob\n",
    ")\n",
    "\n",
    "# Save to a file\n",
    "with open(\"./primaries/frequencies.pkl\", \"wb\") as file:\n",
    "    pickle.dump((single_frequencies, \n",
    "                 paired_frequencies, \n",
    "                 singles_prob, \n",
    "                 paireds_prob), file)\n",
    "\n",
    "with open(\"./primaries/mutation_rate.pkl\", \"wb\") as file:\n",
    "    pickle.dump((single_rate_values,\n",
    "                 paired_rate_values), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from the file\n",
    "with open(\"./primaries/frequencies.pkl\", \"rb\") as file:\n",
    "    (single_frequencies, \n",
    "     paired_frequencies, \n",
    "     singles_prob, \n",
    "     paireds_prob) = pickle.load(file)\n",
    "    \n",
    "with open(\"./primaries/mutation_rate.pkl\", \"rb\") as file:\n",
    "    (single_rate_values,\n",
    "     paired_rate_values) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Grammar Of Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_struct(structures, filename=\"./primaries/structures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itration number: 1\n",
      "Itration number: 2\n",
      "Itration number: 3\n",
      "Itration number: 4\n",
      "Itration number: 5\n",
      "Estimation complete!\n"
     ]
    }
   ],
   "source": [
    "# Train for first time\n",
    "pcfg = PCNF(\"./primaries/structure.cfg\", \"./primaries/structure.pcfg\")\n",
    "pcfg.estimate(\"./primaries/structures.train\", iter_num=5)\n",
    "save_pcfg(pcfg, \"./primaries/structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from trained file\n",
    "pcfg = PCNF(\"./primaries/structure.cfg\", \"./primaries/structure.pcfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
